{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    156060.00000\n",
       "mean          6.89463\n",
       "std           6.57485\n",
       "min           0.00000\n",
       "25%           2.00000\n",
       "50%           4.00000\n",
       "75%           9.00000\n",
       "max          48.00000\n",
       "Name: phracelen, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './Tomatoes/'\n",
    "\n",
    "data = pd.read_csv(\"%s%s\" % (data_path, 'train.tsv'), sep = '\\t')\n",
    "test_data = pd.read_csv(\"%s%s\" % (data_path, 'test.tsv'), sep = '\\t')\n",
    "\n",
    "import re\n",
    "def clean(_str):\n",
    "    return \" \".join(re.findall(\"[0-9a-zA-Z]*\", _str)).strip()\n",
    "def split(_str):\n",
    "    return _str.split()\n",
    "\n",
    "data['Phrase'] = data['Phrase'].apply(clean)\n",
    "test_data['Phrase'] = data['Phrase'].apply(clean)\n",
    "\n",
    "def _len(_str):\n",
    "    return len(_str.split())\n",
    "data['phracelen'] = data['Phrase'].apply(_len)\n",
    "data['phracelen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124848, 5), (31212, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size = 0.8, random_state = 22)\n",
    "\n",
    "for train_index, dev_index in split.split(data, data[['Sentiment']]):\n",
    "    dev_data = data.loc[dev_index]\n",
    "    train_data = data.loc[train_index]\n",
    "train_data.shape, dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_w2v(splited_corpus, w2v_size, min_count):\n",
    "    '''\n",
    "    func: 获取word2vec模型\n",
    "    param: splited_corpus\n",
    "        type: pd.Series\n",
    "        detail: 应当为训练集中所有语料\n",
    "    param: w2v_size\n",
    "        type: int\n",
    "        detail: w2v向量维度\n",
    "    return: w2v_model\n",
    "        type: gensim.models.Word2Vec\n",
    "        detail: 训练的模型只可以使用其transform接口\n",
    "    '''\n",
    "    sentences = [x.split() for x in splited_corpus]\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=min_count, size=w2v_size)\n",
    "    return model\n",
    "\n",
    "def get_w2v_key_vev(w2v_model):\n",
    "    vecs = []\n",
    "    words = []\n",
    "    for word in w2v_model.wv.vocab:\n",
    "        vecs.append(w2v_model[word])\n",
    "        words.append(word)\n",
    "    return words, vecs\n",
    "\n",
    "def get_x_index(x, words):\n",
    "    res = []\n",
    "    for inst in x:\n",
    "        res.append(np.array([words.index(word) for word in inst.split() if word in words]))\n",
    "    return res\n",
    "\n",
    "def max_len(list_2d):\n",
    "    maxlen = 0\n",
    "    for arr in list_2d:\n",
    "        if(len(arr) > maxlen):\n",
    "            maxlen = len(arr)\n",
    "    return maxlen\n",
    "\n",
    "def mean_len(list_2d):\n",
    "    mean_len = 0\n",
    "    for arr in list_2d:\n",
    "        mean_len += len(arr)\n",
    "    return int(mean_len / len(list_2d))\n",
    "\n",
    "def ceil2(num):\n",
    "    res = 2\n",
    "    while res < num:\n",
    "        res *= 2\n",
    "    return res\n",
    "\n",
    "def padding(data2d, max_len, pad_val):\n",
    "    res = []\n",
    "    for index, seq in enumerate(data2d):\n",
    "        if(len(seq) < max_len):\n",
    "            res.append(np.concatenate([seq, np.full([max_len - len(seq)], pad_val)]))\n",
    "        else:\n",
    "            res.append(seq[:max_len])\n",
    "    return res\n",
    "\n",
    "def concat_list_h(list1, list2):\n",
    "    res = []\n",
    "    for i, ele in enumerate(list1):\n",
    "        res.append(np.concatenate([ele, list2[i]]))\n",
    "    return res\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oh_enc = OneHotEncoder()\n",
    "train_y = np.array(list(train_data['Sentiment'])).reshape(-1, 1)\n",
    "train_y = oh_enc.fit_transform(train_y).toarray()\n",
    "dev_y = np.array(list(dev_data['Sentiment'])).reshape(-1, 1)\n",
    "dev_y = oh_enc.fit_transform(dev_y).toarray()\n",
    "corpus = list(train_data['Phrase'])\n",
    "max_seq_len = ceil2(max_len(corpus))\n",
    "mean_seq_len = mean_len(corpus)\n",
    "print(max_seq_len, mean_seq_len)\n",
    "max_seq_len = 16\n",
    "w2v_model = get_w2v(corpus, 300, min_count = 1)\n",
    "words, embedding_matrix = get_w2v_key_vev(w2v_model)\n",
    "embedding_matrix.append([0 for i in range(len(embedding_matrix[0]))])\n",
    "\n",
    "train_x = get_x_index(list(train_data['Phrase']), words)\n",
    "train_x = padding(train_x, max_seq_len, len(embedding_matrix) - 1)\n",
    "\n",
    "dev_x = get_x_index(list(dev_data['Phrase']), words)\n",
    "dev_x = padding(dev_x, max_seq_len, len(embedding_matrix) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf log dir :  tf_logs/run-20191116013652/\n",
      "train epoch 0 / 1000 Done\n",
      "dev acc 0.53697294\n",
      "train loss 1.181351\n",
      "train epoch 1 / 1000 Done\n",
      "train epoch 2 / 1000 Done\n",
      "train epoch 3 / 1000 Done\n",
      "train epoch 4 / 1000 Done\n",
      "train epoch 5 / 1000 Done\n",
      "dev acc 0.56132257\n",
      "train loss 1.0841718\n",
      "train epoch 6 / 1000 Done\n",
      "train epoch 7 / 1000 Done\n",
      "train epoch 8 / 1000 Done\n",
      "train epoch 9 / 1000 Done\n",
      "train epoch 10 / 1000 Done\n",
      "dev acc 0.5711906\n",
      "train loss 1.0480047\n",
      "train epoch 11 / 1000 Done\n",
      "train epoch 12 / 1000 Done\n",
      "train epoch 13 / 1000 Done\n",
      "train epoch 14 / 1000 Done\n",
      "train epoch 15 / 1000 Done\n",
      "dev acc 0.57734203\n",
      "train loss 1.0249176\n",
      "train epoch 16 / 1000 Done\n",
      "train epoch 17 / 1000 Done\n",
      "train epoch 18 / 1000 Done\n",
      "train epoch 19 / 1000 Done\n",
      "train epoch 20 / 1000 Done\n",
      "dev acc 0.5825644\n",
      "train loss 1.0077195\n",
      "train epoch 21 / 1000 Done\n",
      "train epoch 22 / 1000 Done\n",
      "train epoch 23 / 1000 Done\n",
      "train epoch 24 / 1000 Done\n",
      "train epoch 25 / 1000 Done\n",
      "dev acc 0.5864091\n",
      "train loss 0.9944762\n",
      "train epoch 26 / 1000 Done\n",
      "train epoch 27 / 1000 Done\n",
      "train epoch 28 / 1000 Done\n",
      "train epoch 29 / 1000 Done\n",
      "train epoch 30 / 1000 Done\n",
      "dev acc 0.5918557\n",
      "train loss 0.9830635\n",
      "train epoch 31 / 1000 Done\n",
      "train epoch 32 / 1000 Done\n",
      "train epoch 33 / 1000 Done\n",
      "train epoch 34 / 1000 Done\n",
      "train epoch 35 / 1000 Done\n",
      "dev acc 0.5927528\n",
      "train loss 0.9742592\n",
      "train epoch 36 / 1000 Done\n",
      "train epoch 37 / 1000 Done\n",
      "train epoch 38 / 1000 Done\n",
      "train epoch 39 / 1000 Done\n",
      "train epoch 40 / 1000 Done\n",
      "dev acc 0.59435475\n",
      "train loss 0.9650786\n",
      "train epoch 41 / 1000 Done\n",
      "train epoch 42 / 1000 Done\n",
      "train epoch 43 / 1000 Done\n",
      "train epoch 44 / 1000 Done\n",
      "train epoch 45 / 1000 Done\n",
      "dev acc 0.59634113\n",
      "train loss 0.9550771\n",
      "train epoch 46 / 1000 Done\n",
      "train epoch 47 / 1000 Done\n",
      "train epoch 48 / 1000 Done\n",
      "train epoch 49 / 1000 Done\n",
      "train epoch 50 / 1000 Done\n",
      "dev acc 0.5966295\n",
      "train loss 0.9483163\n",
      "train epoch 51 / 1000 Done\n",
      "train epoch 52 / 1000 Done\n",
      "train epoch 53 / 1000 Done\n",
      "train epoch 54 / 1000 Done\n",
      "train epoch 55 / 1000 Done\n",
      "dev acc 0.598712\n",
      "train loss 0.9437809\n",
      "train epoch 56 / 1000 Done\n",
      "train epoch 57 / 1000 Done\n",
      "train epoch 58 / 1000 Done\n",
      "train epoch 59 / 1000 Done\n",
      "train epoch 60 / 1000 Done\n",
      "dev acc 0.6002499\n",
      "train loss 0.93677235\n",
      "train epoch 61 / 1000 Done\n",
      "train epoch 62 / 1000 Done\n",
      "train epoch 63 / 1000 Done\n",
      "train epoch 64 / 1000 Done\n",
      "train epoch 65 / 1000 Done\n",
      "dev acc 0.59938484\n",
      "train loss 0.934628\n",
      "train epoch 66 / 1000 Done\n",
      "train epoch 67 / 1000 Done\n",
      "train epoch 68 / 1000 Done\n",
      "train epoch 69 / 1000 Done\n",
      "train epoch 70 / 1000 Done\n",
      "dev acc 0.6010829\n",
      "train loss 0.9276009\n",
      "train epoch 71 / 1000 Done\n",
      "train epoch 72 / 1000 Done\n",
      "train epoch 73 / 1000 Done\n",
      "train epoch 74 / 1000 Done\n",
      "train epoch 75 / 1000 Done\n",
      "dev acc 0.6017237\n",
      "train loss 0.9242648\n",
      "train epoch 76 / 1000 Done\n",
      "train epoch 77 / 1000 Done\n",
      "train epoch 78 / 1000 Done\n",
      "train epoch 79 / 1000 Done\n",
      "train epoch 80 / 1000 Done\n",
      "dev acc 0.6032616\n",
      "train loss 0.92110044\n",
      "train epoch 81 / 1000 Done\n",
      "train epoch 82 / 1000 Done\n",
      "train epoch 83 / 1000 Done\n",
      "train epoch 84 / 1000 Done\n",
      "train epoch 85 / 1000 Done\n",
      "dev acc 0.60358196\n",
      "train loss 0.91794705\n",
      "train epoch 86 / 1000 Done\n",
      "train epoch 87 / 1000 Done\n",
      "train epoch 88 / 1000 Done\n",
      "train epoch 89 / 1000 Done\n",
      "train epoch 90 / 1000 Done\n",
      "dev acc 0.6056645\n",
      "train loss 0.9133761\n",
      "train epoch 91 / 1000 Done\n",
      "train epoch 92 / 1000 Done\n",
      "train epoch 93 / 1000 Done\n",
      "train epoch 94 / 1000 Done\n",
      "train epoch 95 / 1000 Done\n",
      "dev acc 0.60438293\n",
      "train loss 0.9102697\n",
      "train epoch 96 / 1000 Done\n",
      "train epoch 97 / 1000 Done\n",
      "train epoch 98 / 1000 Done\n",
      "train epoch 99 / 1000 Done\n",
      "train epoch 100 / 1000 Done\n",
      "dev acc 0.60604894\n",
      "train loss 0.90404075\n",
      "train epoch 101 / 1000 Done\n",
      "train epoch 102 / 1000 Done\n",
      "train epoch 103 / 1000 Done\n",
      "train epoch 104 / 1000 Done\n",
      "train epoch 105 / 1000 Done\n",
      "dev acc 0.60627323\n",
      "train loss 0.90324146\n",
      "train epoch 106 / 1000 Done\n",
      "train epoch 107 / 1000 Done\n",
      "train epoch 108 / 1000 Done\n",
      "train epoch 109 / 1000 Done\n",
      "train epoch 110 / 1000 Done\n",
      "dev acc 0.6065616\n",
      "train loss 0.90173244\n",
      "train epoch 111 / 1000 Done\n",
      "train epoch 112 / 1000 Done\n",
      "train epoch 113 / 1000 Done\n",
      "train epoch 114 / 1000 Done\n",
      "train epoch 115 / 1000 Done\n",
      "dev acc 0.607715\n",
      "train loss 0.89558756\n",
      "train epoch 116 / 1000 Done\n",
      "train epoch 117 / 1000 Done\n",
      "train epoch 118 / 1000 Done\n",
      "train epoch 119 / 1000 Done\n",
      "train epoch 120 / 1000 Done\n",
      "dev acc 0.6072664\n",
      "train loss 0.8950271\n",
      "train epoch 121 / 1000 Done\n",
      "train epoch 122 / 1000 Done\n",
      "train epoch 123 / 1000 Done\n",
      "train epoch 124 / 1000 Done\n",
      "train epoch 125 / 1000 Done\n",
      "dev acc 0.60643345\n",
      "train loss 0.89434725\n",
      "train epoch 126 / 1000 Done\n",
      "train epoch 127 / 1000 Done\n",
      "train epoch 128 / 1000 Done\n",
      "train epoch 129 / 1000 Done\n",
      "train epoch 130 / 1000 Done\n",
      "dev acc 0.6080033\n",
      "train loss 0.88936704\n",
      "train epoch 131 / 1000 Done\n",
      "train epoch 132 / 1000 Done\n",
      "train epoch 133 / 1000 Done\n",
      "train epoch 134 / 1000 Done\n",
      "train epoch 135 / 1000 Done\n",
      "dev acc 0.60886836\n",
      "train loss 0.8929382\n",
      "train epoch 136 / 1000 Done\n",
      "train epoch 137 / 1000 Done\n",
      "train epoch 138 / 1000 Done\n",
      "train epoch 139 / 1000 Done\n",
      "train epoch 140 / 1000 Done\n",
      "dev acc 0.60883635\n",
      "train loss 0.88740337\n",
      "train epoch 141 / 1000 Done\n",
      "train epoch 142 / 1000 Done\n",
      "train epoch 143 / 1000 Done\n",
      "train epoch 144 / 1000 Done\n",
      "train epoch 145 / 1000 Done\n",
      "dev acc 0.6089965\n",
      "train loss 0.8840579\n",
      "train epoch 146 / 1000 Done\n",
      "train epoch 147 / 1000 Done\n",
      "train epoch 148 / 1000 Done\n",
      "train epoch 149 / 1000 Done\n",
      "train epoch 150 / 1000 Done\n",
      "dev acc 0.60950917\n",
      "train loss 0.88413733\n",
      "train epoch 151 / 1000 Done\n",
      "train epoch 152 / 1000 Done\n",
      "train epoch 153 / 1000 Done\n",
      "train epoch 154 / 1000 Done\n",
      "train epoch 155 / 1000 Done\n",
      "dev acc 0.61008584\n",
      "train loss 0.8847568\n",
      "train epoch 156 / 1000 Done\n",
      "train epoch 157 / 1000 Done\n",
      "train epoch 158 / 1000 Done\n",
      "train epoch 159 / 1000 Done\n",
      "train epoch 160 / 1000 Done\n",
      "dev acc 0.610214\n",
      "train loss 0.88017446\n",
      "train epoch 161 / 1000 Done\n",
      "train epoch 162 / 1000 Done\n",
      "train epoch 163 / 1000 Done\n",
      "train epoch 164 / 1000 Done\n",
      "train epoch 165 / 1000 Done\n",
      "dev acc 0.6114315\n",
      "train loss 0.8767879\n",
      "train epoch 166 / 1000 Done\n",
      "train epoch 167 / 1000 Done\n",
      "train epoch 168 / 1000 Done\n",
      "train epoch 169 / 1000 Done\n",
      "train epoch 170 / 1000 Done\n",
      "dev acc 0.61220044\n",
      "train loss 0.87491935\n",
      "train epoch 171 / 1000 Done\n",
      "train epoch 172 / 1000 Done\n",
      "train epoch 173 / 1000 Done\n",
      "train epoch 174 / 1000 Done\n",
      "train epoch 175 / 1000 Done\n",
      "dev acc 0.6125849\n",
      "train loss 0.8735812\n",
      "train epoch 176 / 1000 Done\n",
      "train epoch 177 / 1000 Done\n",
      "train epoch 178 / 1000 Done\n",
      "train epoch 179 / 1000 Done\n",
      "train epoch 180 / 1000 Done\n",
      "dev acc 0.61050236\n",
      "train loss 0.8717309\n",
      "train epoch 181 / 1000 Done\n",
      "train epoch 182 / 1000 Done\n",
      "train epoch 183 / 1000 Done\n",
      "train epoch 184 / 1000 Done\n",
      "train epoch 185 / 1000 Done\n",
      "dev acc 0.6120723\n",
      "train loss 0.8716365\n",
      "train epoch 186 / 1000 Done\n",
      "train epoch 187 / 1000 Done\n",
      "train epoch 188 / 1000 Done\n",
      "train epoch 189 / 1000 Done\n",
      "train epoch 190 / 1000 Done\n",
      "dev acc 0.6129694\n",
      "train loss 0.86744153\n",
      "train epoch 191 / 1000 Done\n",
      "train epoch 192 / 1000 Done\n",
      "train epoch 193 / 1000 Done\n",
      "train epoch 194 / 1000 Done\n",
      "train epoch 195 / 1000 Done\n",
      "dev acc 0.61223245\n",
      "train loss 0.87209105\n",
      "train epoch 196 / 1000 Done\n",
      "train epoch 197 / 1000 Done\n",
      "train epoch 198 / 1000 Done\n",
      "train epoch 199 / 1000 Done\n",
      "train epoch 200 / 1000 Done\n",
      "dev acc 0.6115596\n",
      "train loss 0.8658564\n",
      "train epoch 201 / 1000 Done\n",
      "train epoch 202 / 1000 Done\n",
      "train epoch 203 / 1000 Done\n",
      "train epoch 204 / 1000 Done\n",
      "train epoch 205 / 1000 Done\n",
      "dev acc 0.6121043\n",
      "train loss 0.86611676\n",
      "train epoch 206 / 1000 Done\n",
      "train epoch 207 / 1000 Done\n",
      "train epoch 208 / 1000 Done\n",
      "train epoch 209 / 1000 Done\n",
      "train epoch 210 / 1000 Done\n",
      "dev acc 0.6139626\n",
      "train loss 0.86593974\n",
      "train epoch 211 / 1000 Done\n",
      "train epoch 212 / 1000 Done\n",
      "train epoch 213 / 1000 Done\n",
      "train epoch 214 / 1000 Done\n",
      "train epoch 215 / 1000 Done\n",
      "dev acc 0.61290526\n",
      "train loss 0.8628917\n",
      "train epoch 216 / 1000 Done\n",
      "train epoch 217 / 1000 Done\n",
      "train epoch 218 / 1000 Done\n",
      "train epoch 219 / 1000 Done\n",
      "train epoch 220 / 1000 Done\n",
      "dev acc 0.6132257\n",
      "train loss 0.8611909\n",
      "train epoch 221 / 1000 Done\n",
      "train epoch 222 / 1000 Done\n",
      "train epoch 223 / 1000 Done\n",
      "train epoch 224 / 1000 Done\n",
      "train epoch 225 / 1000 Done\n",
      "dev acc 0.61409074\n",
      "train loss 0.8608511\n",
      "train epoch 226 / 1000 Done\n",
      "train epoch 227 / 1000 Done\n",
      "train epoch 228 / 1000 Done\n",
      "train epoch 229 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 230 / 1000 Done\n",
      "dev acc 0.61386645\n",
      "train loss 0.8624177\n",
      "train epoch 231 / 1000 Done\n",
      "train epoch 232 / 1000 Done\n",
      "train epoch 233 / 1000 Done\n",
      "train epoch 234 / 1000 Done\n",
      "train epoch 235 / 1000 Done\n",
      "dev acc 0.6141868\n",
      "train loss 0.8586797\n",
      "train epoch 236 / 1000 Done\n",
      "train epoch 237 / 1000 Done\n",
      "train epoch 238 / 1000 Done\n",
      "train epoch 239 / 1000 Done\n",
      "train epoch 240 / 1000 Done\n",
      "dev acc 0.6139626\n",
      "train loss 0.85582894\n",
      "train epoch 241 / 1000 Done\n",
      "train epoch 242 / 1000 Done\n",
      "train epoch 243 / 1000 Done\n",
      "train epoch 244 / 1000 Done\n",
      "train epoch 245 / 1000 Done\n",
      "dev acc 0.6152121\n",
      "train loss 0.8542088\n",
      "train epoch 246 / 1000 Done\n",
      "train epoch 247 / 1000 Done\n",
      "train epoch 248 / 1000 Done\n",
      "train epoch 249 / 1000 Done\n",
      "train epoch 250 / 1000 Done\n",
      "dev acc 0.6139305\n",
      "train loss 0.85412794\n",
      "train epoch 251 / 1000 Done\n",
      "train epoch 252 / 1000 Done\n",
      "train epoch 253 / 1000 Done\n",
      "train epoch 254 / 1000 Done\n",
      "train epoch 255 / 1000 Done\n",
      "dev acc 0.6139946\n",
      "train loss 0.8547936\n",
      "train epoch 256 / 1000 Done\n",
      "train epoch 257 / 1000 Done\n",
      "train epoch 258 / 1000 Done\n",
      "train epoch 259 / 1000 Done\n",
      "train epoch 260 / 1000 Done\n",
      "dev acc 0.61319363\n",
      "train loss 0.8550714\n",
      "train epoch 261 / 1000 Done\n",
      "train epoch 262 / 1000 Done\n",
      "train epoch 263 / 1000 Done\n",
      "train epoch 264 / 1000 Done\n",
      "train epoch 265 / 1000 Done\n",
      "dev acc 0.6139626\n",
      "train loss 0.8501219\n",
      "train epoch 266 / 1000 Done\n",
      "train epoch 267 / 1000 Done\n",
      "train epoch 268 / 1000 Done\n",
      "train epoch 269 / 1000 Done\n",
      "train epoch 270 / 1000 Done\n",
      "dev acc 0.6146354\n",
      "train loss 0.8508244\n",
      "train epoch 271 / 1000 Done\n",
      "train epoch 272 / 1000 Done\n",
      "train epoch 273 / 1000 Done\n",
      "train epoch 274 / 1000 Done\n",
      "train epoch 275 / 1000 Done\n",
      "dev acc 0.61665386\n",
      "train loss 0.847713\n",
      "train epoch 276 / 1000 Done\n",
      "train epoch 277 / 1000 Done\n",
      "train epoch 278 / 1000 Done\n",
      "train epoch 279 / 1000 Done\n",
      "train epoch 280 / 1000 Done\n",
      "dev acc 0.61457133\n",
      "train loss 0.84791243\n",
      "train epoch 281 / 1000 Done\n",
      "train epoch 282 / 1000 Done\n",
      "train epoch 283 / 1000 Done\n",
      "train epoch 284 / 1000 Done\n",
      "train epoch 285 / 1000 Done\n",
      "dev acc 0.61450726\n",
      "train loss 0.8466121\n",
      "train epoch 286 / 1000 Done\n",
      "train epoch 287 / 1000 Done\n",
      "train epoch 288 / 1000 Done\n",
      "train epoch 289 / 1000 Done\n",
      "train epoch 290 / 1000 Done\n",
      "dev acc 0.6154684\n",
      "train loss 0.844756\n",
      "train epoch 291 / 1000 Done\n",
      "train epoch 292 / 1000 Done\n",
      "train epoch 293 / 1000 Done\n",
      "train epoch 294 / 1000 Done\n",
      "train epoch 295 / 1000 Done\n",
      "dev acc 0.61642957\n",
      "train loss 0.8441499\n",
      "train epoch 296 / 1000 Done\n",
      "train epoch 297 / 1000 Done\n",
      "train epoch 298 / 1000 Done\n",
      "train epoch 299 / 1000 Done\n",
      "train epoch 300 / 1000 Done\n",
      "dev acc 0.61620533\n",
      "train loss 0.8431982\n",
      "train epoch 301 / 1000 Done\n",
      "train epoch 302 / 1000 Done\n",
      "train epoch 303 / 1000 Done\n",
      "train epoch 304 / 1000 Done\n",
      "train epoch 305 / 1000 Done\n",
      "dev acc 0.6141868\n",
      "train loss 0.8434936\n",
      "train epoch 306 / 1000 Done\n",
      "train epoch 307 / 1000 Done\n",
      "train epoch 308 / 1000 Done\n",
      "train epoch 309 / 1000 Done\n",
      "train epoch 310 / 1000 Done\n",
      "dev acc 0.6156927\n",
      "train loss 0.8419982\n",
      "train epoch 311 / 1000 Done\n",
      "train epoch 312 / 1000 Done\n",
      "train epoch 313 / 1000 Done\n",
      "train epoch 314 / 1000 Done\n",
      "train epoch 315 / 1000 Done\n",
      "dev acc 0.6154043\n",
      "train loss 0.84220463\n",
      "train epoch 316 / 1000 Done\n",
      "train epoch 317 / 1000 Done\n",
      "train epoch 318 / 1000 Done\n",
      "train epoch 319 / 1000 Done\n",
      "train epoch 320 / 1000 Done\n",
      "dev acc 0.61687815\n",
      "train loss 0.84097475\n",
      "train epoch 321 / 1000 Done\n",
      "train epoch 322 / 1000 Done\n",
      "train epoch 323 / 1000 Done\n",
      "train epoch 324 / 1000 Done\n",
      "train epoch 325 / 1000 Done\n",
      "dev acc 0.61623734\n",
      "train loss 0.8391421\n",
      "train epoch 326 / 1000 Done\n",
      "train epoch 327 / 1000 Done\n",
      "train epoch 328 / 1000 Done\n",
      "train epoch 329 / 1000 Done\n",
      "train epoch 330 / 1000 Done\n",
      "dev acc 0.6166218\n",
      "train loss 0.84138316\n",
      "train epoch 331 / 1000 Done\n",
      "train epoch 332 / 1000 Done\n",
      "train epoch 333 / 1000 Done\n",
      "train epoch 334 / 1000 Done\n",
      "train epoch 335 / 1000 Done\n",
      "dev acc 0.61646163\n",
      "train loss 0.83790904\n",
      "train epoch 336 / 1000 Done\n",
      "train epoch 337 / 1000 Done\n",
      "train epoch 338 / 1000 Done\n",
      "train epoch 339 / 1000 Done\n",
      "train epoch 340 / 1000 Done\n",
      "dev acc 0.6156927\n",
      "train loss 0.83726174\n",
      "train epoch 341 / 1000 Done\n",
      "train epoch 342 / 1000 Done\n",
      "train epoch 343 / 1000 Done\n",
      "train epoch 344 / 1000 Done\n",
      "train epoch 345 / 1000 Done\n",
      "dev acc 0.61668587\n",
      "train loss 0.83845174\n",
      "train epoch 346 / 1000 Done\n",
      "train epoch 347 / 1000 Done\n",
      "train epoch 348 / 1000 Done\n",
      "train epoch 349 / 1000 Done\n",
      "train epoch 350 / 1000 Done\n",
      "dev acc 0.61575675\n",
      "train loss 0.8367938\n",
      "train epoch 351 / 1000 Done\n",
      "train epoch 352 / 1000 Done\n",
      "train epoch 353 / 1000 Done\n",
      "train epoch 354 / 1000 Done\n",
      "train epoch 355 / 1000 Done\n",
      "dev acc 0.61742276\n",
      "train loss 0.8363763\n",
      "train epoch 356 / 1000 Done\n",
      "train epoch 357 / 1000 Done\n",
      "train epoch 358 / 1000 Done\n",
      "train epoch 359 / 1000 Done\n",
      "train epoch 360 / 1000 Done\n",
      "dev acc 0.61601305\n",
      "train loss 0.833093\n",
      "train epoch 361 / 1000 Done\n",
      "train epoch 362 / 1000 Done\n",
      "train epoch 363 / 1000 Done\n",
      "train epoch 364 / 1000 Done\n",
      "train epoch 365 / 1000 Done\n",
      "dev acc 0.6160771\n",
      "train loss 0.8367268\n",
      "train epoch 366 / 1000 Done\n",
      "train epoch 367 / 1000 Done\n",
      "train epoch 368 / 1000 Done\n",
      "train epoch 369 / 1000 Done\n",
      "train epoch 370 / 1000 Done\n",
      "dev acc 0.6172946\n",
      "train loss 0.83459693\n",
      "train epoch 371 / 1000 Done\n",
      "train epoch 372 / 1000 Done\n",
      "train epoch 373 / 1000 Done\n",
      "train epoch 374 / 1000 Done\n",
      "train epoch 375 / 1000 Done\n",
      "dev acc 0.6161092\n",
      "train loss 0.83186615\n",
      "train epoch 376 / 1000 Done\n",
      "train epoch 377 / 1000 Done\n",
      "train epoch 378 / 1000 Done\n",
      "train epoch 379 / 1000 Done\n",
      "train epoch 380 / 1000 Done\n",
      "dev acc 0.6170383\n",
      "train loss 0.8313448\n",
      "train epoch 381 / 1000 Done\n",
      "train epoch 382 / 1000 Done\n",
      "train epoch 383 / 1000 Done\n",
      "train epoch 384 / 1000 Done\n",
      "train epoch 385 / 1000 Done\n",
      "dev acc 0.61748683\n",
      "train loss 0.83021104\n",
      "train epoch 386 / 1000 Done\n",
      "train epoch 387 / 1000 Done\n",
      "train epoch 388 / 1000 Done\n",
      "train epoch 389 / 1000 Done\n",
      "train epoch 390 / 1000 Done\n",
      "dev acc 0.6173267\n",
      "train loss 0.83136475\n",
      "train epoch 391 / 1000 Done\n",
      "train epoch 392 / 1000 Done\n",
      "train epoch 393 / 1000 Done\n",
      "train epoch 394 / 1000 Done\n",
      "train epoch 395 / 1000 Done\n",
      "dev acc 0.61649364\n",
      "train loss 0.8307916\n",
      "train epoch 396 / 1000 Done\n",
      "train epoch 397 / 1000 Done\n",
      "train epoch 398 / 1000 Done\n",
      "train epoch 399 / 1000 Done\n",
      "train epoch 400 / 1000 Done\n",
      "dev acc 0.61674994\n",
      "train loss 0.830692\n",
      "train epoch 401 / 1000 Done\n",
      "train epoch 402 / 1000 Done\n",
      "train epoch 403 / 1000 Done\n",
      "train epoch 404 / 1000 Done\n",
      "train epoch 405 / 1000 Done\n",
      "dev acc 0.6170704\n",
      "train loss 0.8303252\n",
      "train epoch 406 / 1000 Done\n",
      "train epoch 407 / 1000 Done\n",
      "train epoch 408 / 1000 Done\n",
      "train epoch 409 / 1000 Done\n",
      "train epoch 410 / 1000 Done\n",
      "dev acc 0.618416\n",
      "train loss 0.82791173\n",
      "train epoch 411 / 1000 Done\n",
      "train epoch 412 / 1000 Done\n",
      "train epoch 413 / 1000 Done\n",
      "train epoch 414 / 1000 Done\n",
      "train epoch 415 / 1000 Done\n",
      "dev acc 0.6174548\n",
      "train loss 0.8237465\n",
      "train epoch 416 / 1000 Done\n",
      "train epoch 417 / 1000 Done\n",
      "train epoch 418 / 1000 Done\n",
      "train epoch 419 / 1000 Done\n",
      "train epoch 420 / 1000 Done\n",
      "dev acc 0.618416\n",
      "train loss 0.8263257\n",
      "train epoch 421 / 1000 Done\n",
      "train epoch 422 / 1000 Done\n",
      "train epoch 423 / 1000 Done\n",
      "train epoch 424 / 1000 Done\n",
      "train epoch 425 / 1000 Done\n",
      "dev acc 0.6170383\n",
      "train loss 0.8246235\n",
      "train epoch 426 / 1000 Done\n",
      "train epoch 427 / 1000 Done\n",
      "train epoch 428 / 1000 Done\n",
      "train epoch 429 / 1000 Done\n",
      "train epoch 430 / 1000 Done\n",
      "dev acc 0.61716646\n",
      "train loss 0.82420236\n",
      "train epoch 431 / 1000 Done\n",
      "train epoch 432 / 1000 Done\n",
      "train epoch 433 / 1000 Done\n",
      "train epoch 434 / 1000 Done\n",
      "train epoch 435 / 1000 Done\n",
      "dev acc 0.61880046\n",
      "train loss 0.8238957\n",
      "train epoch 436 / 1000 Done\n",
      "train epoch 437 / 1000 Done\n",
      "train epoch 438 / 1000 Done\n",
      "train epoch 439 / 1000 Done\n",
      "train epoch 440 / 1000 Done\n",
      "dev acc 0.6171024\n",
      "train loss 0.8242195\n",
      "train epoch 441 / 1000 Done\n",
      "train epoch 442 / 1000 Done\n",
      "train epoch 443 / 1000 Done\n",
      "train epoch 444 / 1000 Done\n",
      "train epoch 445 / 1000 Done\n",
      "dev acc 0.6177432\n",
      "train loss 0.8230261\n",
      "train epoch 446 / 1000 Done\n",
      "train epoch 447 / 1000 Done\n",
      "train epoch 448 / 1000 Done\n",
      "train epoch 449 / 1000 Done\n",
      "train epoch 450 / 1000 Done\n",
      "dev acc 0.6170383\n",
      "train loss 0.82085985\n",
      "train epoch 451 / 1000 Done\n",
      "train epoch 452 / 1000 Done\n",
      "train epoch 453 / 1000 Done\n",
      "train epoch 454 / 1000 Done\n",
      "train epoch 455 / 1000 Done\n",
      "dev acc 0.6180956\n",
      "train loss 0.82267976\n",
      "train epoch 456 / 1000 Done\n",
      "train epoch 457 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 458 / 1000 Done\n",
      "train epoch 459 / 1000 Done\n",
      "train epoch 460 / 1000 Done\n",
      "dev acc 0.61857617\n",
      "train loss 0.8222022\n",
      "train epoch 461 / 1000 Done\n",
      "train epoch 462 / 1000 Done\n",
      "train epoch 463 / 1000 Done\n",
      "train epoch 464 / 1000 Done\n",
      "train epoch 465 / 1000 Done\n",
      "dev acc 0.6193451\n",
      "train loss 0.8202025\n",
      "train epoch 466 / 1000 Done\n",
      "train epoch 467 / 1000 Done\n",
      "train epoch 468 / 1000 Done\n",
      "train epoch 469 / 1000 Done\n",
      "train epoch 470 / 1000 Done\n",
      "dev acc 0.6180315\n",
      "train loss 0.82243997\n",
      "train epoch 471 / 1000 Done\n",
      "train epoch 472 / 1000 Done\n",
      "train epoch 473 / 1000 Done\n",
      "train epoch 474 / 1000 Done\n",
      "train epoch 475 / 1000 Done\n",
      "dev acc 0.61831987\n",
      "train loss 0.818692\n",
      "train epoch 476 / 1000 Done\n",
      "train epoch 477 / 1000 Done\n",
      "train epoch 478 / 1000 Done\n",
      "train epoch 479 / 1000 Done\n",
      "train epoch 480 / 1000 Done\n",
      "dev acc 0.61806357\n",
      "train loss 0.819718\n",
      "train epoch 481 / 1000 Done\n",
      "train epoch 482 / 1000 Done\n",
      "train epoch 483 / 1000 Done\n",
      "train epoch 484 / 1000 Done\n",
      "train epoch 485 / 1000 Done\n",
      "dev acc 0.6179674\n",
      "train loss 0.8177335\n",
      "train epoch 486 / 1000 Done\n",
      "train epoch 487 / 1000 Done\n",
      "train epoch 488 / 1000 Done\n",
      "train epoch 489 / 1000 Done\n",
      "train epoch 490 / 1000 Done\n",
      "dev acc 0.61860824\n",
      "train loss 0.8189799\n",
      "train epoch 491 / 1000 Done\n",
      "train epoch 492 / 1000 Done\n",
      "train epoch 493 / 1000 Done\n",
      "train epoch 494 / 1000 Done\n",
      "train epoch 495 / 1000 Done\n",
      "dev acc 0.618416\n",
      "train loss 0.81571525\n",
      "train epoch 496 / 1000 Done\n",
      "train epoch 497 / 1000 Done\n",
      "train epoch 498 / 1000 Done\n",
      "train epoch 499 / 1000 Done\n",
      "train epoch 500 / 1000 Done\n",
      "dev acc 0.6179995\n",
      "train loss 0.81796175\n",
      "train epoch 501 / 1000 Done\n",
      "train epoch 502 / 1000 Done\n",
      "train epoch 503 / 1000 Done\n",
      "train epoch 504 / 1000 Done\n",
      "train epoch 505 / 1000 Done\n",
      "dev acc 0.6189607\n",
      "train loss 0.8173174\n",
      "train epoch 506 / 1000 Done\n",
      "train epoch 507 / 1000 Done\n",
      "train epoch 508 / 1000 Done\n",
      "train epoch 509 / 1000 Done\n",
      "train epoch 510 / 1000 Done\n",
      "dev acc 0.6181597\n",
      "train loss 0.8179479\n",
      "train epoch 511 / 1000 Done\n",
      "train epoch 512 / 1000 Done\n",
      "train epoch 513 / 1000 Done\n",
      "train epoch 514 / 1000 Done\n",
      "train epoch 515 / 1000 Done\n",
      "dev acc 0.61787134\n",
      "train loss 0.8168561\n",
      "train epoch 516 / 1000 Done\n",
      "train epoch 517 / 1000 Done\n",
      "train epoch 518 / 1000 Done\n",
      "train epoch 519 / 1000 Done\n",
      "train epoch 520 / 1000 Done\n",
      "dev acc 0.6186723\n",
      "train loss 0.8164414\n",
      "train epoch 521 / 1000 Done\n",
      "train epoch 522 / 1000 Done\n",
      "train epoch 523 / 1000 Done\n",
      "train epoch 524 / 1000 Done\n",
      "train epoch 525 / 1000 Done\n",
      "dev acc 0.6198898\n",
      "train loss 0.81704485\n",
      "train epoch 526 / 1000 Done\n",
      "train epoch 527 / 1000 Done\n",
      "train epoch 528 / 1000 Done\n",
      "train epoch 529 / 1000 Done\n",
      "train epoch 530 / 1000 Done\n",
      "dev acc 0.61831987\n",
      "train loss 0.811548\n",
      "train epoch 531 / 1000 Done\n",
      "train epoch 532 / 1000 Done\n",
      "train epoch 533 / 1000 Done\n",
      "train epoch 534 / 1000 Done\n",
      "train epoch 535 / 1000 Done\n",
      "dev acc 0.61831987\n",
      "train loss 0.8146754\n",
      "train epoch 536 / 1000 Done\n",
      "train epoch 537 / 1000 Done\n",
      "train epoch 538 / 1000 Done\n",
      "train epoch 539 / 1000 Done\n",
      "train epoch 540 / 1000 Done\n",
      "dev acc 0.6201141\n",
      "train loss 0.81153965\n",
      "train epoch 541 / 1000 Done\n",
      "train epoch 542 / 1000 Done\n",
      "train epoch 543 / 1000 Done\n",
      "train epoch 544 / 1000 Done\n",
      "train epoch 545 / 1000 Done\n",
      "dev acc 0.61950535\n",
      "train loss 0.815994\n",
      "train epoch 546 / 1000 Done\n",
      "train epoch 547 / 1000 Done\n",
      "train epoch 548 / 1000 Done\n",
      "train epoch 549 / 1000 Done\n",
      "train epoch 550 / 1000 Done\n",
      "dev acc 0.6179995\n",
      "train loss 0.8133006\n",
      "train epoch 551 / 1000 Done\n",
      "train epoch 552 / 1000 Done\n",
      "train epoch 553 / 1000 Done\n",
      "train epoch 554 / 1000 Done\n",
      "train epoch 555 / 1000 Done\n",
      "dev acc 0.61976165\n",
      "train loss 0.81188583\n",
      "train epoch 556 / 1000 Done\n",
      "train epoch 557 / 1000 Done\n",
      "train epoch 558 / 1000 Done\n",
      "train epoch 559 / 1000 Done\n",
      "train epoch 560 / 1000 Done\n",
      "dev acc 0.6190888\n",
      "train loss 0.8112234\n",
      "train epoch 561 / 1000 Done\n",
      "train epoch 562 / 1000 Done\n",
      "train epoch 563 / 1000 Done\n",
      "train epoch 564 / 1000 Done\n",
      "train epoch 565 / 1000 Done\n",
      "dev acc 0.6177111\n",
      "train loss 0.81648016\n",
      "train epoch 566 / 1000 Done\n",
      "train epoch 567 / 1000 Done\n",
      "train epoch 568 / 1000 Done\n",
      "train epoch 569 / 1000 Done\n",
      "train epoch 570 / 1000 Done\n",
      "dev acc 0.619249\n",
      "train loss 0.81229913\n",
      "train epoch 571 / 1000 Done\n",
      "train epoch 572 / 1000 Done\n",
      "train epoch 573 / 1000 Done\n",
      "train epoch 574 / 1000 Done\n",
      "train epoch 575 / 1000 Done\n",
      "dev acc 0.61950535\n",
      "train loss 0.81096596\n",
      "train epoch 576 / 1000 Done\n",
      "train epoch 577 / 1000 Done\n",
      "train epoch 578 / 1000 Done\n",
      "train epoch 579 / 1000 Done\n",
      "train epoch 580 / 1000 Done\n",
      "dev acc 0.6199859\n",
      "train loss 0.80863965\n",
      "train epoch 581 / 1000 Done\n",
      "train epoch 582 / 1000 Done\n",
      "train epoch 583 / 1000 Done\n",
      "train epoch 584 / 1000 Done\n",
      "train epoch 585 / 1000 Done\n",
      "dev acc 0.61912084\n",
      "train loss 0.8118283\n",
      "train epoch 586 / 1000 Done\n",
      "train epoch 587 / 1000 Done\n",
      "train epoch 588 / 1000 Done\n",
      "train epoch 589 / 1000 Done\n",
      "train epoch 590 / 1000 Done\n",
      "dev acc 0.61937714\n",
      "train loss 0.8090671\n",
      "train epoch 591 / 1000 Done\n",
      "train epoch 592 / 1000 Done\n",
      "train epoch 593 / 1000 Done\n",
      "train epoch 594 / 1000 Done\n",
      "train epoch 595 / 1000 Done\n",
      "dev acc 0.62001795\n",
      "train loss 0.80816203\n",
      "train epoch 596 / 1000 Done\n",
      "train epoch 597 / 1000 Done\n",
      "train epoch 598 / 1000 Done\n",
      "train epoch 599 / 1000 Done\n",
      "train epoch 600 / 1000 Done\n",
      "dev acc 0.619249\n",
      "train loss 0.8108461\n",
      "train epoch 601 / 1000 Done\n",
      "train epoch 602 / 1000 Done\n",
      "train epoch 603 / 1000 Done\n",
      "train epoch 604 / 1000 Done\n",
      "train epoch 605 / 1000 Done\n",
      "dev acc 0.6205626\n",
      "train loss 0.80859625\n",
      "train epoch 606 / 1000 Done\n",
      "train epoch 607 / 1000 Done\n",
      "train epoch 608 / 1000 Done\n",
      "train epoch 609 / 1000 Done\n",
      "train epoch 610 / 1000 Done\n",
      "dev acc 0.6211073\n",
      "train loss 0.80750954\n",
      "train epoch 611 / 1000 Done\n",
      "train epoch 612 / 1000 Done\n",
      "train epoch 613 / 1000 Done\n",
      "train epoch 614 / 1000 Done\n",
      "train epoch 615 / 1000 Done\n",
      "dev acc 0.62101114\n",
      "train loss 0.80723864\n",
      "train epoch 616 / 1000 Done\n",
      "train epoch 617 / 1000 Done\n",
      "train epoch 618 / 1000 Done\n",
      "train epoch 619 / 1000 Done\n",
      "train epoch 620 / 1000 Done\n",
      "dev acc 0.6204024\n",
      "train loss 0.80836904\n",
      "train epoch 621 / 1000 Done\n",
      "train epoch 622 / 1000 Done\n",
      "train epoch 623 / 1000 Done\n",
      "train epoch 624 / 1000 Done\n",
      "train epoch 625 / 1000 Done\n",
      "dev acc 0.6205946\n",
      "train loss 0.80874485\n",
      "train epoch 626 / 1000 Done\n",
      "train epoch 627 / 1000 Done\n",
      "train epoch 628 / 1000 Done\n",
      "train epoch 629 / 1000 Done\n",
      "train epoch 630 / 1000 Done\n",
      "dev acc 0.6216199\n",
      "train loss 0.8060686\n",
      "train epoch 631 / 1000 Done\n",
      "train epoch 632 / 1000 Done\n",
      "train epoch 633 / 1000 Done\n",
      "train epoch 634 / 1000 Done\n",
      "train epoch 635 / 1000 Done\n",
      "dev acc 0.6211073\n",
      "train loss 0.8030066\n",
      "train epoch 636 / 1000 Done\n",
      "train epoch 637 / 1000 Done\n",
      "train epoch 638 / 1000 Done\n",
      "train epoch 639 / 1000 Done\n",
      "train epoch 640 / 1000 Done\n",
      "dev acc 0.62094706\n",
      "train loss 0.8024969\n",
      "train epoch 641 / 1000 Done\n",
      "train epoch 642 / 1000 Done\n",
      "train epoch 643 / 1000 Done\n",
      "train epoch 644 / 1000 Done\n",
      "train epoch 645 / 1000 Done\n",
      "dev acc 0.6206267\n",
      "train loss 0.80453444\n",
      "train epoch 646 / 1000 Done\n",
      "train epoch 647 / 1000 Done\n",
      "train epoch 648 / 1000 Done\n",
      "train epoch 649 / 1000 Done\n",
      "train epoch 650 / 1000 Done\n",
      "dev acc 0.62017816\n",
      "train loss 0.80395055\n",
      "train epoch 651 / 1000 Done\n",
      "train epoch 652 / 1000 Done\n",
      "train epoch 653 / 1000 Done\n",
      "train epoch 654 / 1000 Done\n",
      "train epoch 655 / 1000 Done\n",
      "dev acc 0.61928105\n",
      "train loss 0.8026376\n",
      "train epoch 656 / 1000 Done\n",
      "train epoch 657 / 1000 Done\n",
      "train epoch 658 / 1000 Done\n",
      "train epoch 659 / 1000 Done\n",
      "train epoch 660 / 1000 Done\n",
      "dev acc 0.6196014\n",
      "train loss 0.8068396\n",
      "train epoch 661 / 1000 Done\n",
      "train epoch 662 / 1000 Done\n",
      "train epoch 663 / 1000 Done\n",
      "train epoch 664 / 1000 Done\n",
      "train epoch 665 / 1000 Done\n",
      "dev acc 0.6199218\n",
      "train loss 0.8029381\n",
      "train epoch 666 / 1000 Done\n",
      "train epoch 667 / 1000 Done\n",
      "train epoch 668 / 1000 Done\n",
      "train epoch 669 / 1000 Done\n",
      "train epoch 670 / 1000 Done\n",
      "dev acc 0.6203063\n",
      "train loss 0.8011537\n",
      "train epoch 671 / 1000 Done\n",
      "train epoch 672 / 1000 Done\n",
      "train epoch 673 / 1000 Done\n",
      "train epoch 674 / 1000 Done\n",
      "train epoch 675 / 1000 Done\n",
      "dev acc 0.62117136\n",
      "train loss 0.80150926\n",
      "train epoch 676 / 1000 Done\n",
      "train epoch 677 / 1000 Done\n",
      "train epoch 678 / 1000 Done\n",
      "train epoch 679 / 1000 Done\n",
      "train epoch 680 / 1000 Done\n",
      "dev acc 0.6195694\n",
      "train loss 0.8013762\n",
      "train epoch 681 / 1000 Done\n",
      "train epoch 682 / 1000 Done\n",
      "train epoch 683 / 1000 Done\n",
      "train epoch 684 / 1000 Done\n",
      "train epoch 685 / 1000 Done\n",
      "dev acc 0.6213315\n",
      "train loss 0.8004046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 686 / 1000 Done\n",
      "train epoch 687 / 1000 Done\n",
      "train epoch 688 / 1000 Done\n",
      "train epoch 689 / 1000 Done\n",
      "train epoch 690 / 1000 Done\n",
      "dev acc 0.62097913\n",
      "train loss 0.8033712\n",
      "train epoch 691 / 1000 Done\n",
      "train epoch 692 / 1000 Done\n",
      "train epoch 693 / 1000 Done\n",
      "train epoch 694 / 1000 Done\n",
      "train epoch 695 / 1000 Done\n",
      "dev acc 0.6203704\n",
      "train loss 0.8028211\n",
      "train epoch 696 / 1000 Done\n",
      "train epoch 697 / 1000 Done\n",
      "train epoch 698 / 1000 Done\n",
      "train epoch 699 / 1000 Done\n",
      "train epoch 700 / 1000 Done\n",
      "dev acc 0.62053055\n",
      "train loss 0.80031866\n",
      "train epoch 701 / 1000 Done\n",
      "train epoch 702 / 1000 Done\n",
      "train epoch 703 / 1000 Done\n",
      "train epoch 704 / 1000 Done\n",
      "train epoch 705 / 1000 Done\n",
      "dev acc 0.62097913\n",
      "train loss 0.8023297\n",
      "train epoch 706 / 1000 Done\n",
      "train epoch 707 / 1000 Done\n",
      "train epoch 708 / 1000 Done\n",
      "train epoch 709 / 1000 Done\n",
      "train epoch 710 / 1000 Done\n",
      "dev acc 0.620851\n",
      "train loss 0.8009662\n",
      "train epoch 711 / 1000 Done\n",
      "train epoch 712 / 1000 Done\n",
      "train epoch 713 / 1000 Done\n",
      "train epoch 714 / 1000 Done\n",
      "train epoch 715 / 1000 Done\n",
      "dev acc 0.6194412\n",
      "train loss 0.8015985\n",
      "train epoch 716 / 1000 Done\n",
      "train epoch 717 / 1000 Done\n",
      "train epoch 718 / 1000 Done\n",
      "train epoch 719 / 1000 Done\n",
      "train epoch 720 / 1000 Done\n",
      "dev acc 0.62017816\n",
      "train loss 0.8007863\n",
      "train epoch 721 / 1000 Done\n",
      "train epoch 722 / 1000 Done\n",
      "train epoch 723 / 1000 Done\n",
      "train epoch 724 / 1000 Done\n",
      "train epoch 725 / 1000 Done\n",
      "dev acc 0.61979365\n",
      "train loss 0.7983239\n",
      "train epoch 726 / 1000 Done\n",
      "train epoch 727 / 1000 Done\n",
      "train epoch 728 / 1000 Done\n",
      "train epoch 729 / 1000 Done\n",
      "train epoch 730 / 1000 Done\n",
      "dev acc 0.61928105\n",
      "train loss 0.7967788\n",
      "train epoch 731 / 1000 Done\n",
      "train epoch 732 / 1000 Done\n",
      "train epoch 733 / 1000 Done\n",
      "train epoch 734 / 1000 Done\n",
      "train epoch 735 / 1000 Done\n",
      "dev acc 0.62075484\n",
      "train loss 0.79766554\n",
      "train epoch 736 / 1000 Done\n",
      "train epoch 737 / 1000 Done\n",
      "train epoch 738 / 1000 Done\n",
      "train epoch 739 / 1000 Done\n",
      "train epoch 740 / 1000 Done\n",
      "dev acc 0.61928105\n",
      "train loss 0.79952997\n",
      "train epoch 741 / 1000 Done\n",
      "train epoch 742 / 1000 Done\n",
      "train epoch 743 / 1000 Done\n",
      "train epoch 744 / 1000 Done\n",
      "train epoch 745 / 1000 Done\n",
      "dev acc 0.62027425\n",
      "train loss 0.7996106\n",
      "train epoch 746 / 1000 Done\n",
      "train epoch 747 / 1000 Done\n",
      "train epoch 748 / 1000 Done\n",
      "train epoch 749 / 1000 Done\n",
      "train epoch 750 / 1000 Done\n",
      "dev acc 0.6196335\n",
      "train loss 0.7986246\n",
      "train epoch 751 / 1000 Done\n",
      "train epoch 752 / 1000 Done\n",
      "train epoch 753 / 1000 Done\n",
      "train epoch 754 / 1000 Done\n",
      "train epoch 755 / 1000 Done\n",
      "dev acc 0.621716\n",
      "train loss 0.7974047\n",
      "train epoch 756 / 1000 Done\n",
      "train epoch 757 / 1000 Done\n",
      "train epoch 758 / 1000 Done\n",
      "train epoch 759 / 1000 Done\n",
      "train epoch 760 / 1000 Done\n",
      "dev acc 0.62142766\n",
      "train loss 0.79731303\n",
      "train epoch 761 / 1000 Done\n",
      "train epoch 762 / 1000 Done\n",
      "train epoch 763 / 1000 Done\n",
      "train epoch 764 / 1000 Done\n",
      "train epoch 765 / 1000 Done\n",
      "dev acc 0.6204024\n",
      "train loss 0.79613227\n",
      "train epoch 766 / 1000 Done\n",
      "train epoch 767 / 1000 Done\n",
      "train epoch 768 / 1000 Done\n",
      "train epoch 769 / 1000 Done\n",
      "train epoch 770 / 1000 Done\n",
      "dev acc 0.6205946\n",
      "train loss 0.7963155\n",
      "train epoch 771 / 1000 Done\n",
      "train epoch 772 / 1000 Done\n",
      "train epoch 773 / 1000 Done\n",
      "train epoch 774 / 1000 Done\n",
      "train epoch 775 / 1000 Done\n",
      "dev acc 0.62024224\n",
      "train loss 0.79449886\n",
      "train epoch 776 / 1000 Done\n",
      "train epoch 777 / 1000 Done\n",
      "train epoch 778 / 1000 Done\n",
      "train epoch 779 / 1000 Done\n",
      "train epoch 780 / 1000 Done\n",
      "dev acc 0.6212995\n",
      "train loss 0.7954719\n",
      "train epoch 781 / 1000 Done\n",
      "train epoch 782 / 1000 Done\n",
      "train epoch 783 / 1000 Done\n",
      "train epoch 784 / 1000 Done\n",
      "train epoch 785 / 1000 Done\n",
      "dev acc 0.6227413\n",
      "train loss 0.79290414\n",
      "train epoch 786 / 1000 Done\n",
      "train epoch 787 / 1000 Done\n",
      "train epoch 788 / 1000 Done\n",
      "train epoch 789 / 1000 Done\n",
      "train epoch 790 / 1000 Done\n",
      "dev acc 0.62101114\n",
      "train loss 0.7950676\n",
      "train epoch 791 / 1000 Done\n",
      "train epoch 792 / 1000 Done\n",
      "train epoch 793 / 1000 Done\n",
      "train epoch 794 / 1000 Done\n",
      "train epoch 795 / 1000 Done\n",
      "dev acc 0.62097913\n",
      "train loss 0.7960754\n",
      "train epoch 796 / 1000 Done\n",
      "train epoch 797 / 1000 Done\n",
      "train epoch 798 / 1000 Done\n",
      "train epoch 799 / 1000 Done\n",
      "train epoch 800 / 1000 Done\n",
      "dev acc 0.62126744\n",
      "train loss 0.7947145\n",
      "train epoch 801 / 1000 Done\n",
      "train epoch 802 / 1000 Done\n",
      "train epoch 803 / 1000 Done\n",
      "train epoch 804 / 1000 Done\n",
      "train epoch 805 / 1000 Done\n",
      "dev acc 0.6205626\n",
      "train loss 0.79348564\n",
      "train epoch 806 / 1000 Done\n",
      "train epoch 807 / 1000 Done\n",
      "train epoch 808 / 1000 Done\n",
      "train epoch 809 / 1000 Done\n",
      "train epoch 810 / 1000 Done\n",
      "dev acc 0.6215558\n",
      "train loss 0.79393095\n",
      "train epoch 811 / 1000 Done\n",
      "train epoch 812 / 1000 Done\n",
      "train epoch 813 / 1000 Done\n",
      "train epoch 814 / 1000 Done\n",
      "train epoch 815 / 1000 Done\n",
      "dev acc 0.6207869\n",
      "train loss 0.7923275\n",
      "train epoch 816 / 1000 Done\n",
      "train epoch 817 / 1000 Done\n",
      "train epoch 818 / 1000 Done\n",
      "train epoch 819 / 1000 Done\n",
      "train epoch 820 / 1000 Done\n",
      "dev acc 0.62200433\n",
      "train loss 0.7913891\n",
      "train epoch 821 / 1000 Done\n",
      "train epoch 822 / 1000 Done\n",
      "train epoch 823 / 1000 Done\n",
      "train epoch 824 / 1000 Done\n",
      "train epoch 825 / 1000 Done\n",
      "dev acc 0.6216199\n",
      "train loss 0.7926723\n",
      "train epoch 826 / 1000 Done\n",
      "train epoch 827 / 1000 Done\n",
      "train epoch 828 / 1000 Done\n",
      "train epoch 829 / 1000 Done\n",
      "train epoch 830 / 1000 Done\n",
      "dev acc 0.62097913\n",
      "train loss 0.7929645\n",
      "train epoch 831 / 1000 Done\n",
      "train epoch 832 / 1000 Done\n",
      "train epoch 833 / 1000 Done\n",
      "train epoch 834 / 1000 Done\n",
      "train epoch 835 / 1000 Done\n",
      "dev acc 0.6199539\n",
      "train loss 0.7899805\n",
      "train epoch 836 / 1000 Done\n",
      "train epoch 837 / 1000 Done\n",
      "train epoch 838 / 1000 Done\n",
      "train epoch 839 / 1000 Done\n",
      "train epoch 840 / 1000 Done\n",
      "dev acc 0.62120336\n",
      "train loss 0.7897426\n",
      "train epoch 841 / 1000 Done\n",
      "train epoch 842 / 1000 Done\n",
      "train epoch 843 / 1000 Done\n",
      "train epoch 844 / 1000 Done\n",
      "train epoch 845 / 1000 Done\n",
      "dev acc 0.62123543\n",
      "train loss 0.7913533\n",
      "train epoch 846 / 1000 Done\n",
      "train epoch 847 / 1000 Done\n",
      "train epoch 848 / 1000 Done\n",
      "train epoch 849 / 1000 Done\n",
      "train epoch 850 / 1000 Done\n",
      "dev acc 0.6216199\n",
      "train loss 0.7918414\n",
      "train epoch 851 / 1000 Done\n",
      "train epoch 852 / 1000 Done\n",
      "train epoch 853 / 1000 Done\n",
      "train epoch 854 / 1000 Done\n",
      "train epoch 855 / 1000 Done\n",
      "dev acc 0.6213956\n",
      "train loss 0.79234385\n",
      "train epoch 856 / 1000 Done\n",
      "train epoch 857 / 1000 Done\n",
      "train epoch 858 / 1000 Done\n",
      "train epoch 859 / 1000 Done\n",
      "train epoch 860 / 1000 Done\n",
      "dev acc 0.6196655\n",
      "train loss 0.7918417\n",
      "train epoch 861 / 1000 Done\n",
      "train epoch 862 / 1000 Done\n",
      "train epoch 863 / 1000 Done\n",
      "train epoch 864 / 1000 Done\n",
      "train epoch 865 / 1000 Done\n",
      "dev acc 0.6213956\n",
      "train loss 0.791948\n",
      "train epoch 866 / 1000 Done\n",
      "train epoch 867 / 1000 Done\n",
      "train epoch 868 / 1000 Done\n",
      "train epoch 869 / 1000 Done\n",
      "train epoch 870 / 1000 Done\n",
      "dev acc 0.62267715\n",
      "train loss 0.7912278\n",
      "train epoch 871 / 1000 Done\n",
      "train epoch 872 / 1000 Done\n",
      "train epoch 873 / 1000 Done\n",
      "train epoch 874 / 1000 Done\n",
      "train epoch 875 / 1000 Done\n",
      "dev acc 0.6212995\n",
      "train loss 0.79056513\n",
      "train epoch 876 / 1000 Done\n",
      "train epoch 877 / 1000 Done\n",
      "train epoch 878 / 1000 Done\n",
      "train epoch 879 / 1000 Done\n",
      "train epoch 880 / 1000 Done\n",
      "dev acc 0.62091506\n",
      "train loss 0.7906238\n",
      "train epoch 881 / 1000 Done\n",
      "train epoch 882 / 1000 Done\n",
      "train epoch 883 / 1000 Done\n",
      "train epoch 884 / 1000 Done\n",
      "train epoch 885 / 1000 Done\n",
      "dev acc 0.62117136\n",
      "train loss 0.7888283\n",
      "train epoch 886 / 1000 Done\n",
      "train epoch 887 / 1000 Done\n",
      "train epoch 888 / 1000 Done\n",
      "train epoch 889 / 1000 Done\n",
      "train epoch 890 / 1000 Done\n",
      "dev acc 0.6212995\n",
      "train loss 0.78823864\n",
      "train epoch 891 / 1000 Done\n",
      "train epoch 892 / 1000 Done\n",
      "train epoch 893 / 1000 Done\n",
      "train epoch 894 / 1000 Done\n",
      "train epoch 895 / 1000 Done\n",
      "dev acc 0.6213315\n",
      "train loss 0.78817433\n",
      "train epoch 896 / 1000 Done\n",
      "train epoch 897 / 1000 Done\n",
      "train epoch 898 / 1000 Done\n",
      "train epoch 899 / 1000 Done\n",
      "train epoch 900 / 1000 Done\n",
      "dev acc 0.6218442\n",
      "train loss 0.7889813\n",
      "train epoch 901 / 1000 Done\n",
      "train epoch 902 / 1000 Done\n",
      "train epoch 903 / 1000 Done\n",
      "train epoch 904 / 1000 Done\n",
      "train epoch 905 / 1000 Done\n",
      "dev acc 0.6212995\n",
      "train loss 0.7901368\n",
      "train epoch 906 / 1000 Done\n",
      "train epoch 907 / 1000 Done\n",
      "train epoch 908 / 1000 Done\n",
      "train epoch 909 / 1000 Done\n",
      "train epoch 910 / 1000 Done\n",
      "dev acc 0.6221005\n",
      "train loss 0.79117876\n",
      "train epoch 911 / 1000 Done\n",
      "train epoch 912 / 1000 Done\n",
      "train epoch 913 / 1000 Done\n",
      "train epoch 914 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 915 / 1000 Done\n",
      "dev acc 0.61937714\n",
      "train loss 0.7903876\n",
      "train epoch 916 / 1000 Done\n",
      "train epoch 917 / 1000 Done\n",
      "train epoch 918 / 1000 Done\n",
      "train epoch 919 / 1000 Done\n",
      "train epoch 920 / 1000 Done\n",
      "dev acc 0.6206267\n",
      "train loss 0.79021597\n",
      "train epoch 921 / 1000 Done\n",
      "train epoch 922 / 1000 Done\n",
      "train epoch 923 / 1000 Done\n",
      "train epoch 924 / 1000 Done\n",
      "train epoch 925 / 1000 Done\n",
      "dev acc 0.622517\n",
      "train loss 0.7864519\n",
      "train epoch 926 / 1000 Done\n",
      "train epoch 927 / 1000 Done\n",
      "train epoch 928 / 1000 Done\n",
      "train epoch 929 / 1000 Done\n",
      "train epoch 930 / 1000 Done\n",
      "dev acc 0.62149173\n",
      "train loss 0.7870389\n",
      "train epoch 931 / 1000 Done\n",
      "train epoch 932 / 1000 Done\n",
      "train epoch 933 / 1000 Done\n",
      "train epoch 934 / 1000 Done\n",
      "train epoch 935 / 1000 Done\n",
      "dev acc 0.6201141\n",
      "train loss 0.7896\n",
      "train epoch 936 / 1000 Done\n",
      "train epoch 937 / 1000 Done\n",
      "train epoch 938 / 1000 Done\n",
      "train epoch 939 / 1000 Done\n",
      "train epoch 940 / 1000 Done\n",
      "dev acc 0.6205946\n",
      "train loss 0.78821605\n",
      "train epoch 941 / 1000 Done\n",
      "train epoch 942 / 1000 Done\n",
      "train epoch 943 / 1000 Done\n",
      "train epoch 944 / 1000 Done\n",
      "train epoch 945 / 1000 Done\n",
      "dev acc 0.62232476\n",
      "train loss 0.78615093\n",
      "train epoch 946 / 1000 Done\n",
      "train epoch 947 / 1000 Done\n",
      "train epoch 948 / 1000 Done\n",
      "train epoch 949 / 1000 Done\n",
      "train epoch 950 / 1000 Done\n",
      "dev acc 0.62216455\n",
      "train loss 0.78495073\n",
      "train epoch 951 / 1000 Done\n",
      "train epoch 952 / 1000 Done\n",
      "train epoch 953 / 1000 Done\n",
      "train epoch 954 / 1000 Done\n",
      "train epoch 955 / 1000 Done\n",
      "dev acc 0.62094706\n",
      "train loss 0.78631395\n",
      "train epoch 956 / 1000 Done\n",
      "train epoch 957 / 1000 Done\n",
      "train epoch 958 / 1000 Done\n",
      "train epoch 959 / 1000 Done\n",
      "train epoch 960 / 1000 Done\n",
      "dev acc 0.6218762\n",
      "train loss 0.7864781\n",
      "train epoch 961 / 1000 Done\n",
      "train epoch 962 / 1000 Done\n",
      "train epoch 963 / 1000 Done\n",
      "train epoch 964 / 1000 Done\n",
      "train epoch 965 / 1000 Done\n",
      "dev acc 0.6195694\n",
      "train loss 0.7826471\n",
      "train epoch 966 / 1000 Done\n",
      "train epoch 967 / 1000 Done\n",
      "train epoch 968 / 1000 Done\n",
      "train epoch 969 / 1000 Done\n",
      "train epoch 970 / 1000 Done\n",
      "dev acc 0.6213636\n",
      "train loss 0.7858243\n",
      "train epoch 971 / 1000 Done\n",
      "train epoch 972 / 1000 Done\n",
      "train epoch 973 / 1000 Done\n",
      "train epoch 974 / 1000 Done\n",
      "train epoch 975 / 1000 Done\n",
      "dev acc 0.6216199\n",
      "train loss 0.784771\n",
      "train epoch 976 / 1000 Done\n",
      "train epoch 977 / 1000 Done\n",
      "train epoch 978 / 1000 Done\n",
      "train epoch 979 / 1000 Done\n",
      "train epoch 980 / 1000 Done\n",
      "dev acc 0.62174803\n",
      "train loss 0.78635293\n",
      "train epoch 981 / 1000 Done\n",
      "train epoch 982 / 1000 Done\n",
      "train epoch 983 / 1000 Done\n",
      "train epoch 984 / 1000 Done\n",
      "train epoch 985 / 1000 Done\n",
      "dev acc 0.6218121\n",
      "train loss 0.7854435\n",
      "train epoch 986 / 1000 Done\n",
      "train epoch 987 / 1000 Done\n",
      "train epoch 988 / 1000 Done\n",
      "train epoch 989 / 1000 Done\n",
      "train epoch 990 / 1000 Done\n",
      "dev acc 0.62165195\n",
      "train loss 0.7845784\n",
      "train epoch 991 / 1000 Done\n",
      "train epoch 992 / 1000 Done\n",
      "train epoch 993 / 1000 Done\n",
      "train epoch 994 / 1000 Done\n",
      "train epoch 995 / 1000 Done\n",
      "dev acc 0.62190825\n",
      "train loss 0.7847378\n",
      "train epoch 996 / 1000 Done\n",
      "train epoch 997 / 1000 Done\n",
      "train epoch 998 / 1000 Done\n",
      "train epoch 999 / 1000 Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from datetime import datetime\n",
    "\n",
    "class typical:\n",
    "    def __init__(self, seq_len, num_classes, batch_seqs_num, embedding_matrix, embedding_size, filter_sizes,\n",
    "                num_filters, conv_activate_fn = tf.nn.relu, fcl_activate_fn = tf.nn.relu, learning_rate = 0.01,\n",
    "                n_epochs = 100, rate_decay_steps = 1000, rate_decay_rate = 0.99, regulation_rate= 0.0001,\n",
    "                sum_root_dir = \"tf_logs\", drop_out_prob = 0.5):\n",
    "        self.seq_len = seq_len\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_seqs_num = batch_seqs_num\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_size = embedding_size\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.conv_activate_fn = conv_activate_fn\n",
    "        self.fcl_activate_fn = fcl_activate_fn\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.rate_decay_steps = rate_decay_steps\n",
    "        self.rate_decay_rate = rate_decay_rate\n",
    "        self.regulation_rate = regulation_rate\n",
    "        self.log_dir = self.log_dir(sum_root_dir)\n",
    "        self.drop_out_prob = drop_out_prob\n",
    "        self.graph = tf.Graph()\n",
    "    \n",
    "    def log_dir(self, root_logdir):\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "        log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "        return log_dir\n",
    "    \n",
    "    def build(self):\n",
    "        with Qself.graph.as_default():\n",
    "            self.input_x = tf.placeholder(dtype = tf.int32, shape = [None, self.seq_len], name = \"input_x\")\n",
    "            self.input_y = tf.placeholder(dtype = tf.int32, shape = [None, self.num_classes], name = \"input_y\")\n",
    "            self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "            self.global_step = tf.Variable(0, trainable = False)\n",
    "            '''self.learning_rate_ = tf.train.exponential_decay(\n",
    "                self.learning_rate,\n",
    "                self.global_step,\n",
    "                self.rate_decay_steps,\n",
    "                self.rate_decay_rate\n",
    "            )'''\n",
    "            with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "                W = tf.Variable(\n",
    "                        tf.random_uniform(self.embedding_matrix.shape, -1.0, 1.0),\n",
    "                        name=\"W\")\n",
    "                self.embedding_matrix_ = tf.constant(self.embedding_matrix, name = \"embedding_matrix\", dtype = tf.float32)\n",
    "                self.embedded = tf.expand_dims(tf.nn.embedding_lookup(self.embedding_matrix_, self.input_x), -1,\n",
    "                                               name = \"embedded_output\")\n",
    "            self.pooled_outputs = []\n",
    "            for filter_size in self.filter_sizes:\n",
    "                with tf.name_scope(\"conv_maxpool\"):\n",
    "                    filter_shape = [filter_size, self.embedding_size, 1, self.num_filters]\n",
    "                    filter_weight = tf.Variable(tf.truncated_normal(filter_shape, stddev = 0.1), name = \"filter_weight\")\n",
    "                    filter_bias = tf.Variable(tf.truncated_normal([self.num_filters], stddev = 0.1), name = \"filter_bias\")\n",
    "                    conv_output = self.conv_activate_fn(tf.nn.bias_add(tf.nn.conv2d(\n",
    "                        self.embedded,\n",
    "                        filter_weight,\n",
    "                        strides = [1, 1, 1, 1],\n",
    "                        padding = 'VALID',\n",
    "                    ), filter_bias, name = \"conv_output\"), name = \"act_conv_output\")\n",
    "                    pooled_output = tf.nn.max_pool(conv_output,\n",
    "                                                  ksize = [1, self.seq_len - filter_size + 1, 1, 1],\n",
    "                                                  strides = [1, 1, 1, 1],\n",
    "                                                  padding = \"VALID\",\n",
    "                                                  name = \"pooled_output\")\n",
    "                    self.pooled_outputs.append(pooled_output)\n",
    "            #拼接\n",
    "            self.total_filters_num = self.num_filters * len(self.filter_sizes)\n",
    "            self.concated_output = tf.concat(self.pooled_outputs, 3)\n",
    "            self.reduced_concated_output = tf.reshape(self.concated_output, [-1, self.total_filters_num], \n",
    "                                                      name = \"conv_maxpool_output\")\n",
    "\n",
    "            with tf.name_scope(\"dropout\"):\n",
    "                self.droped_conv_output = tf.nn.dropout(self.reduced_concated_output, self.dropout_keep_prob)\n",
    "\n",
    "            with tf.name_scope(\"full_connect\"):\n",
    "                self.fcl_weight = tf.Variable(tf.truncated_normal([self.total_filters_num, self.num_classes],\n",
    "                                                                 stddev = 0.1), name = 'fcl_weight')\n",
    "                self.fcl_bias = tf.Variable(tf.constant(0.1, shape = [self.num_classes]), name = 'fcl_bias')\n",
    "                self.fcl_output = tf.nn.bias_add(tf.matmul(self.droped_conv_output, self.fcl_weight),\n",
    "                                                self.fcl_bias, name = \"fcl_output\")\n",
    "\n",
    "            self.prediction = self.fcl_output\n",
    "            with tf.name_scope(\"regulation\"):\n",
    "                self.regularizer = tf.contrib.layers.l2_regularizer(self.regulation_rate)\n",
    "                self.regulation = self.regularizer(self.fcl_weight) + self.regularizer(self.fcl_bias)\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits = self.prediction, labels = self.input_y,  \n",
    "                    ), name = \"cross_entrophy\") + self.regulation\n",
    "            with tf.name_scope(\"target\"):\n",
    "                self.train_correct = tf.equal(tf.arg_max(self.prediction, 1), tf.arg_max(self.input_y, 1), name = \"correct\")\n",
    "                self.train_acc = tf.reduce_mean(tf.cast(self.train_correct, tf.float32), name = \"acc\")\n",
    "                self.train_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits = tf.cast(tf.arg_max(self.prediction, 1), tf.float32), labels = tf.cast(tf.arg_max(self.input_y, 1), tf.float32)\n",
    "                        , name = \"train_loss\"\n",
    "                    ))\n",
    "            with tf.name_scope(\"summary\"):\n",
    "                self.loss_sum = tf.summary.scalar(\"loss\", self.loss)\n",
    "                self.acc_sum = tf.summary.scalar(\"acc\", self.train_acc)\n",
    "                self.sum = tf.summary.merge_all()\n",
    "                self.filewriter = tf.summary.FileWriter(self.log_dir, tf.get_default_graph())\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            self.train_step = self.optimizer.minimize(self.loss, global_step = self.global_step)\n",
    "            \n",
    "    \n",
    "    def fit(self, x, y, dev_x = None, dev_y = None, test_x = None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.dev_x = dev_x\n",
    "        self.dev_y = dev_y\n",
    "        self.test_x = test_x\n",
    "    \n",
    "    def train(self):\n",
    "        print('tf log dir : ', self.log_dir)\n",
    "        n_batches = int(np.ceil(len(self.x) / self.batch_seqs_num))\n",
    "        batch_size = self.batch_seqs_num\n",
    "        dev_feed_dict = {\n",
    "            self.input_x : self.dev_x,\n",
    "            self.input_y : self.dev_y,\n",
    "            self.dropout_keep_prob : 1.0\n",
    "        }\n",
    "        train_feed_dict = {\n",
    "            self.input_x : self.x[:10000],\n",
    "            self.input_y : self.y[:10000],\n",
    "            self.dropout_keep_prob : 1.0\n",
    "        }\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config = config, graph = self.graph) as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(self.n_epochs):\n",
    "                for batch_index in range(n_batches):\n",
    "                    batch_x = self.x[batch_size * batch_index : (batch_index + 1) * batch_size]\n",
    "                    batch_y = self.y[batch_size * batch_index : (batch_index + 1) * batch_size]\n",
    "                    feed_dict = {\n",
    "                        self.input_x : batch_x,\n",
    "                        self.input_y : batch_y,\n",
    "                        self.dropout_keep_prob : self.drop_out_prob\n",
    "                    }\n",
    "                    sess.run(self.train_step, feed_dict = feed_dict)\n",
    "                    step = epoch * n_batches + batch_index\n",
    "                print('train epoch %d / %d Done' % (epoch, self.n_epochs))\n",
    "                if(epoch % 5 == 0):\n",
    "                    print('dev acc', self.train_acc.eval(feed_dict = dev_feed_dict))\n",
    "                    print('train loss', self.loss.eval(feed_dict = train_feed_dict))\n",
    "                    dev_acc_str = self.acc_sum.eval(feed_dict = dev_feed_dict)\n",
    "                    train_loss_str = self.loss_sum.eval(feed_dict = train_feed_dict)\n",
    "                    self.filewriter.add_summary(dev_acc_str, step)\n",
    "                    self.filewriter.add_summary(train_loss_str, step)\n",
    "            \n",
    "    \n",
    "m = typical(max_seq_len, 5, 32, np.array(embedding_matrix), len(embedding_matrix[0]), [2,3,4,5], 128, learning_rate = 0.00015,\n",
    "            n_epochs = 1000, rate_decay_steps = 1000000, drop_out_prob = 0.4)\n",
    "m.build()\n",
    "m.fit(train_x, train_y, dev_x, dev_y)\n",
    "m.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
