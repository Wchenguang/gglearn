{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    156060.00000\n",
       "mean          6.89463\n",
       "std           6.57485\n",
       "min           0.00000\n",
       "25%           2.00000\n",
       "50%           4.00000\n",
       "75%           9.00000\n",
       "max          48.00000\n",
       "Name: phracelen, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './Tomatoes/'\n",
    "\n",
    "data = pd.read_csv(\"%s%s\" % (data_path, 'train.tsv'), sep = '\\t')\n",
    "test_data = pd.read_csv(\"%s%s\" % (data_path, 'test.tsv'), sep = '\\t')\n",
    "\n",
    "import re\n",
    "def clean(_str):\n",
    "    return \" \".join(re.findall(\"[0-9a-zA-Z]*\", _str)).strip()\n",
    "def split(_str):\n",
    "    return _str.split()\n",
    "\n",
    "data['Phrase'] = data['Phrase'].apply(clean)\n",
    "test_data['Phrase'] = data['Phrase'].apply(clean)\n",
    "\n",
    "def _len(_str):\n",
    "    return len(_str.split())\n",
    "data['phracelen'] = data['Phrase'].apply(_len)\n",
    "data['phracelen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124848, 5), (31212, 5))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size = 0.8, random_state = 22)\n",
    "\n",
    "for train_index, dev_index in split.split(data, data[['Sentiment']]):\n",
    "    dev_data = data.loc[dev_index]\n",
    "    train_data = data.loc[train_index]\n",
    "train_data.shape, dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dutir_2t/wangchenguang/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_w2v(splited_corpus, w2v_size, min_count):\n",
    "    '''\n",
    "    func: 获取word2vec模型\n",
    "    param: splited_corpus\n",
    "        type: pd.Series\n",
    "        detail: 应当为训练集中所有语料\n",
    "    param: w2v_size\n",
    "        type: int\n",
    "        detail: w2v向量维度\n",
    "    return: w2v_model\n",
    "        type: gensim.models.Word2Vec\n",
    "        detail: 训练的模型只可以使用其transform接口\n",
    "    '''\n",
    "    sentences = [x.split() for x in splited_corpus]\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=min_count, size=w2v_size)\n",
    "    return model\n",
    "\n",
    "def get_w2v_key_vev(w2v_model):\n",
    "    vecs = []\n",
    "    words = []\n",
    "    for word in w2v_model.wv.vocab:\n",
    "        vecs.append(w2v_model[word])\n",
    "        words.append(word)\n",
    "    return words, vecs\n",
    "\n",
    "def get_x_index(x, words):\n",
    "    res = []\n",
    "    for inst in x:\n",
    "        res.append(np.array([words.index(word) for word in inst.split() if word in words]))\n",
    "    return res\n",
    "\n",
    "def max_len(list_2d):\n",
    "    maxlen = 0\n",
    "    for arr in list_2d:\n",
    "        if(len(arr) > maxlen):\n",
    "            maxlen = len(arr)\n",
    "    return maxlen\n",
    "\n",
    "def mean_len(list_2d):\n",
    "    mean_len = 0\n",
    "    for arr in list_2d:\n",
    "        mean_len += len(arr)\n",
    "    return int(mean_len / len(list_2d))\n",
    "\n",
    "def ceil2(num):\n",
    "    res = 2\n",
    "    while res < num:\n",
    "        res *= 2\n",
    "    return res\n",
    "\n",
    "def padding(data2d, max_len, pad_val):\n",
    "    res = []\n",
    "    for index, seq in enumerate(data2d):\n",
    "        if(len(seq) < max_len):\n",
    "            res.append(np.concatenate([seq, np.full([max_len - len(seq)], pad_val)]))\n",
    "        else:\n",
    "            res.append(seq[:max_len])\n",
    "    return res\n",
    "\n",
    "def concat_list_h(list1, list2):\n",
    "    res = []\n",
    "    for i, ele in enumerate(list1):\n",
    "        res.append(np.concatenate([ele, list2[i]]))\n",
    "    return res\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oh_enc = OneHotEncoder()\n",
    "train_y = np.array(list(train_data['Sentiment'])).reshape(-1, 1)\n",
    "train_y = oh_enc.fit_transform(train_y).toarray()\n",
    "dev_y = np.array(list(dev_data['Sentiment'])).reshape(-1, 1)\n",
    "dev_y = oh_enc.fit_transform(dev_y).toarray()\n",
    "corpus = list(train_data['Phrase'])\n",
    "max_seq_len = ceil2(max_len(corpus))\n",
    "mean_seq_len = mean_len(corpus)\n",
    "print(max_seq_len, mean_seq_len)\n",
    "max_seq_len = 16\n",
    "w2v_model = get_w2v(corpus, 300, min_count = 1)\n",
    "words, embedding_matrix = get_w2v_key_vev(w2v_model)\n",
    "embedding_matrix.append([0 for i in range(len(embedding_matrix[0]))])\n",
    "\n",
    "train_x = get_x_index(list(train_data['Phrase']), words)\n",
    "train_x = padding(train_x, max_seq_len, len(embedding_matrix) - 1)\n",
    "\n",
    "dev_x = get_x_index(list(dev_data['Phrase']), words)\n",
    "dev_x = padding(dev_x, max_seq_len, len(embedding_matrix) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf log dir :  tf_logs/run-20191117000924/\n",
      "train epoch 0 / 1000 Done\n",
      "dev acc 0.5099321\n",
      "train loss 1.3566505\n",
      "train epoch 1 / 1000 Done\n",
      "train epoch 2 / 1000 Done\n",
      "train epoch 3 / 1000 Done\n",
      "train epoch 4 / 1000 Done\n",
      "train epoch 5 / 1000 Done\n",
      "dev acc 0.5099962\n",
      "train loss 1.3502307\n",
      "train epoch 6 / 1000 Done\n",
      "train epoch 7 / 1000 Done\n",
      "train epoch 8 / 1000 Done\n",
      "train epoch 9 / 1000 Done\n",
      "train epoch 10 / 1000 Done\n",
      "dev acc 0.51287967\n",
      "train loss 1.3463413\n",
      "train epoch 11 / 1000 Done\n",
      "train epoch 12 / 1000 Done\n",
      "train epoch 13 / 1000 Done\n",
      "train epoch 14 / 1000 Done\n",
      "train epoch 15 / 1000 Done\n",
      "dev acc 0.5144816\n",
      "train loss 1.3405045\n",
      "train epoch 16 / 1000 Done\n",
      "train epoch 17 / 1000 Done\n",
      "train epoch 18 / 1000 Done\n",
      "train epoch 19 / 1000 Done\n",
      "train epoch 20 / 1000 Done\n",
      "dev acc 0.5184865\n",
      "train loss 1.335283\n",
      "train epoch 21 / 1000 Done\n",
      "train epoch 22 / 1000 Done\n",
      "train epoch 23 / 1000 Done\n",
      "train epoch 24 / 1000 Done\n",
      "train epoch 25 / 1000 Done\n",
      "dev acc 0.5270409\n",
      "train loss 1.3273197\n",
      "train epoch 26 / 1000 Done\n",
      "train epoch 27 / 1000 Done\n",
      "train epoch 28 / 1000 Done\n",
      "train epoch 29 / 1000 Done\n",
      "train epoch 30 / 1000 Done\n",
      "dev acc 0.52668846\n",
      "train loss 1.326063\n",
      "train epoch 31 / 1000 Done\n",
      "train epoch 32 / 1000 Done\n",
      "train epoch 33 / 1000 Done\n",
      "train epoch 34 / 1000 Done\n",
      "train epoch 35 / 1000 Done\n",
      "dev acc 0.5354351\n",
      "train loss 1.3214437\n",
      "train epoch 36 / 1000 Done\n",
      "train epoch 37 / 1000 Done\n",
      "train epoch 38 / 1000 Done\n",
      "train epoch 39 / 1000 Done\n",
      "train epoch 40 / 1000 Done\n",
      "dev acc 0.53319234\n",
      "train loss 1.320684\n",
      "train epoch 41 / 1000 Done\n",
      "train epoch 42 / 1000 Done\n",
      "train epoch 43 / 1000 Done\n",
      "train epoch 44 / 1000 Done\n",
      "train epoch 45 / 1000 Done\n",
      "dev acc 0.53646034\n",
      "train loss 1.316695\n",
      "train epoch 46 / 1000 Done\n",
      "train epoch 47 / 1000 Done\n",
      "train epoch 48 / 1000 Done\n",
      "train epoch 49 / 1000 Done\n",
      "train epoch 50 / 1000 Done\n",
      "dev acc 0.5385108\n",
      "train loss 1.3153435\n",
      "train epoch 51 / 1000 Done\n",
      "train epoch 52 / 1000 Done\n",
      "train epoch 53 / 1000 Done\n",
      "train epoch 54 / 1000 Done\n",
      "train epoch 55 / 1000 Done\n",
      "dev acc 0.5396963\n",
      "train loss 1.3132294\n",
      "train epoch 56 / 1000 Done\n",
      "train epoch 57 / 1000 Done\n",
      "train epoch 58 / 1000 Done\n",
      "train epoch 59 / 1000 Done\n",
      "train epoch 60 / 1000 Done\n",
      "dev acc 0.53992057\n",
      "train loss 1.3140591\n",
      "train epoch 61 / 1000 Done\n",
      "train epoch 62 / 1000 Done\n",
      "train epoch 63 / 1000 Done\n",
      "train epoch 64 / 1000 Done\n",
      "train epoch 65 / 1000 Done\n",
      "dev acc 0.5398244\n",
      "train loss 1.3124738\n",
      "train epoch 66 / 1000 Done\n",
      "train epoch 67 / 1000 Done\n",
      "train epoch 68 / 1000 Done\n",
      "train epoch 69 / 1000 Done\n",
      "train epoch 70 / 1000 Done\n",
      "dev acc 0.54328465\n",
      "train loss 1.3101981\n",
      "train epoch 71 / 1000 Done\n",
      "train epoch 72 / 1000 Done\n",
      "train epoch 73 / 1000 Done\n",
      "train epoch 74 / 1000 Done\n",
      "train epoch 75 / 1000 Done\n",
      "dev acc 0.54328465\n",
      "train loss 1.3096926\n",
      "train epoch 76 / 1000 Done\n",
      "train epoch 77 / 1000 Done\n",
      "train epoch 78 / 1000 Done\n",
      "train epoch 79 / 1000 Done\n",
      "train epoch 80 / 1000 Done\n",
      "dev acc 0.542772\n",
      "train loss 1.3070707\n",
      "train epoch 81 / 1000 Done\n",
      "train epoch 82 / 1000 Done\n",
      "train epoch 83 / 1000 Done\n",
      "train epoch 84 / 1000 Done\n",
      "train epoch 85 / 1000 Done\n",
      "dev acc 0.544406\n",
      "train loss 1.3080031\n",
      "train epoch 86 / 1000 Done\n",
      "train epoch 87 / 1000 Done\n",
      "train epoch 88 / 1000 Done\n",
      "train epoch 89 / 1000 Done\n",
      "train epoch 90 / 1000 Done\n",
      "dev acc 0.5449827\n",
      "train loss 1.3046068\n",
      "train epoch 91 / 1000 Done\n",
      "train epoch 92 / 1000 Done\n",
      "train epoch 93 / 1000 Done\n",
      "train epoch 94 / 1000 Done\n",
      "train epoch 95 / 1000 Done\n",
      "dev acc 0.5458157\n",
      "train loss 1.302328\n",
      "train epoch 96 / 1000 Done\n",
      "train epoch 97 / 1000 Done\n",
      "train epoch 98 / 1000 Done\n",
      "train epoch 99 / 1000 Done\n",
      "train epoch 100 / 1000 Done\n",
      "dev acc 0.5464885\n",
      "train loss 1.3035955\n",
      "train epoch 101 / 1000 Done\n",
      "train epoch 102 / 1000 Done\n",
      "train epoch 103 / 1000 Done\n",
      "train epoch 104 / 1000 Done\n",
      "train epoch 105 / 1000 Done\n",
      "dev acc 0.54882735\n",
      "train loss 1.2999487\n",
      "train epoch 106 / 1000 Done\n",
      "train epoch 107 / 1000 Done\n",
      "train epoch 108 / 1000 Done\n",
      "train epoch 109 / 1000 Done\n",
      "train epoch 110 / 1000 Done\n",
      "dev acc 0.54853904\n",
      "train loss 1.3025752\n",
      "train epoch 111 / 1000 Done\n",
      "train epoch 112 / 1000 Done\n",
      "train epoch 113 / 1000 Done\n",
      "train epoch 114 / 1000 Done\n",
      "train epoch 115 / 1000 Done\n",
      "dev acc 0.550173\n",
      "train loss 1.3005211\n",
      "train epoch 116 / 1000 Done\n",
      "train epoch 117 / 1000 Done\n",
      "train epoch 118 / 1000 Done\n",
      "train epoch 119 / 1000 Done\n",
      "train epoch 120 / 1000 Done\n",
      "dev acc 0.5505254\n",
      "train loss 1.298544\n",
      "train epoch 121 / 1000 Done\n",
      "train epoch 122 / 1000 Done\n",
      "train epoch 123 / 1000 Done\n",
      "train epoch 124 / 1000 Done\n",
      "train epoch 125 / 1000 Done\n",
      "dev acc 0.5516468\n",
      "train loss 1.296149\n",
      "train epoch 126 / 1000 Done\n",
      "train epoch 127 / 1000 Done\n",
      "train epoch 128 / 1000 Done\n",
      "train epoch 129 / 1000 Done\n",
      "train epoch 130 / 1000 Done\n",
      "dev acc 0.54998076\n",
      "train loss 1.2962152\n",
      "train epoch 131 / 1000 Done\n",
      "train epoch 132 / 1000 Done\n",
      "train epoch 133 / 1000 Done\n",
      "train epoch 134 / 1000 Done\n",
      "train epoch 135 / 1000 Done\n",
      "dev acc 0.5503012\n",
      "train loss 1.2942033\n",
      "train epoch 136 / 1000 Done\n",
      "train epoch 137 / 1000 Done\n",
      "train epoch 138 / 1000 Done\n",
      "train epoch 139 / 1000 Done\n",
      "train epoch 140 / 1000 Done\n",
      "dev acc 0.55209535\n",
      "train loss 1.2931134\n",
      "train epoch 141 / 1000 Done\n",
      "train epoch 142 / 1000 Done\n",
      "train epoch 143 / 1000 Done\n",
      "train epoch 144 / 1000 Done\n",
      "train epoch 145 / 1000 Done\n",
      "dev acc 0.5509099\n",
      "train loss 1.2932129\n",
      "train epoch 146 / 1000 Done\n",
      "train epoch 147 / 1000 Done\n",
      "train epoch 148 / 1000 Done\n",
      "train epoch 149 / 1000 Done\n",
      "train epoch 150 / 1000 Done\n",
      "dev acc 0.5544342\n",
      "train loss 1.2910771\n",
      "train epoch 151 / 1000 Done\n",
      "train epoch 152 / 1000 Done\n",
      "train epoch 153 / 1000 Done\n",
      "train epoch 154 / 1000 Done\n",
      "train epoch 155 / 1000 Done\n",
      "dev acc 0.55408174\n",
      "train loss 1.2908561\n",
      "train epoch 156 / 1000 Done\n",
      "train epoch 157 / 1000 Done\n",
      "train epoch 158 / 1000 Done\n",
      "train epoch 159 / 1000 Done\n",
      "train epoch 160 / 1000 Done\n",
      "dev acc 0.5543701\n",
      "train loss 1.2907759\n",
      "train epoch 161 / 1000 Done\n",
      "train epoch 162 / 1000 Done\n",
      "train epoch 163 / 1000 Done\n",
      "train epoch 164 / 1000 Done\n",
      "train epoch 165 / 1000 Done\n",
      "dev acc 0.555107\n",
      "train loss 1.289099\n",
      "train epoch 166 / 1000 Done\n",
      "train epoch 167 / 1000 Done\n",
      "train epoch 168 / 1000 Done\n",
      "train epoch 169 / 1000 Done\n",
      "train epoch 170 / 1000 Done\n",
      "dev acc 0.5569012\n",
      "train loss 1.2898577\n",
      "train epoch 171 / 1000 Done\n",
      "train epoch 172 / 1000 Done\n",
      "train epoch 173 / 1000 Done\n",
      "train epoch 174 / 1000 Done\n",
      "train epoch 175 / 1000 Done\n",
      "dev acc 0.5576701\n",
      "train loss 1.2879354\n",
      "train epoch 176 / 1000 Done\n",
      "train epoch 177 / 1000 Done\n",
      "train epoch 178 / 1000 Done\n",
      "train epoch 179 / 1000 Done\n",
      "train epoch 180 / 1000 Done\n",
      "dev acc 0.5581828\n",
      "train loss 1.2861967\n",
      "train epoch 181 / 1000 Done\n",
      "train epoch 182 / 1000 Done\n",
      "train epoch 183 / 1000 Done\n",
      "train epoch 184 / 1000 Done\n",
      "train epoch 185 / 1000 Done\n",
      "dev acc 0.5555235\n",
      "train loss 1.287918\n",
      "train epoch 186 / 1000 Done\n",
      "train epoch 187 / 1000 Done\n",
      "train epoch 188 / 1000 Done\n",
      "train epoch 189 / 1000 Done\n",
      "train epoch 190 / 1000 Done\n",
      "dev acc 0.5590798\n",
      "train loss 1.286728\n",
      "train epoch 191 / 1000 Done\n",
      "train epoch 192 / 1000 Done\n",
      "train epoch 193 / 1000 Done\n",
      "train epoch 194 / 1000 Done\n",
      "train epoch 195 / 1000 Done\n",
      "dev acc 0.5574459\n",
      "train loss 1.2840371\n",
      "train epoch 196 / 1000 Done\n",
      "train epoch 197 / 1000 Done\n",
      "train epoch 198 / 1000 Done\n",
      "train epoch 199 / 1000 Done\n",
      "train epoch 200 / 1000 Done\n",
      "dev acc 0.55875945\n",
      "train loss 1.2810729\n",
      "train epoch 201 / 1000 Done\n",
      "train epoch 202 / 1000 Done\n",
      "train epoch 203 / 1000 Done\n",
      "train epoch 204 / 1000 Done\n",
      "train epoch 205 / 1000 Done\n",
      "dev acc 0.5579585\n",
      "train loss 1.2826593\n",
      "train epoch 206 / 1000 Done\n",
      "train epoch 207 / 1000 Done\n",
      "train epoch 208 / 1000 Done\n",
      "train epoch 209 / 1000 Done\n",
      "train epoch 210 / 1000 Done\n",
      "dev acc 0.5617391\n",
      "train loss 1.282081\n",
      "train epoch 211 / 1000 Done\n",
      "train epoch 212 / 1000 Done\n",
      "train epoch 213 / 1000 Done\n",
      "train epoch 214 / 1000 Done\n",
      "train epoch 215 / 1000 Done\n",
      "dev acc 0.56263614\n",
      "train loss 1.280747\n",
      "train epoch 216 / 1000 Done\n",
      "train epoch 217 / 1000 Done\n",
      "train epoch 218 / 1000 Done\n",
      "train epoch 219 / 1000 Done\n",
      "train epoch 220 / 1000 Done\n",
      "dev acc 0.55943227\n",
      "train loss 1.282769\n",
      "train epoch 221 / 1000 Done\n",
      "train epoch 222 / 1000 Done\n",
      "train epoch 223 / 1000 Done\n",
      "train epoch 224 / 1000 Done\n",
      "train epoch 225 / 1000 Done\n",
      "dev acc 0.55943227\n",
      "train loss 1.2805778\n",
      "train epoch 226 / 1000 Done\n",
      "train epoch 227 / 1000 Done\n",
      "train epoch 228 / 1000 Done\n",
      "train epoch 229 / 1000 Done\n",
      "train epoch 230 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc 0.55805457\n",
      "train loss 1.282232\n",
      "train epoch 231 / 1000 Done\n",
      "train epoch 232 / 1000 Done\n",
      "train epoch 233 / 1000 Done\n",
      "train epoch 234 / 1000 Done\n",
      "train epoch 235 / 1000 Done\n",
      "dev acc 0.5624439\n",
      "train loss 1.2809722\n",
      "train epoch 236 / 1000 Done\n",
      "train epoch 237 / 1000 Done\n",
      "train epoch 238 / 1000 Done\n",
      "train epoch 239 / 1000 Done\n",
      "train epoch 240 / 1000 Done\n",
      "dev acc 0.559208\n",
      "train loss 1.2775995\n",
      "train epoch 241 / 1000 Done\n",
      "train epoch 242 / 1000 Done\n",
      "train epoch 243 / 1000 Done\n",
      "train epoch 244 / 1000 Done\n",
      "train epoch 245 / 1000 Done\n",
      "dev acc 0.56330895\n",
      "train loss 1.2788327\n",
      "train epoch 246 / 1000 Done\n",
      "train epoch 247 / 1000 Done\n",
      "train epoch 248 / 1000 Done\n",
      "train epoch 249 / 1000 Done\n",
      "train epoch 250 / 1000 Done\n",
      "dev acc 0.563341\n",
      "train loss 1.2770001\n",
      "train epoch 251 / 1000 Done\n",
      "train epoch 252 / 1000 Done\n",
      "train epoch 253 / 1000 Done\n",
      "train epoch 254 / 1000 Done\n",
      "train epoch 255 / 1000 Done\n",
      "dev acc 0.56353325\n",
      "train loss 1.2774004\n",
      "train epoch 256 / 1000 Done\n",
      "train epoch 257 / 1000 Done\n",
      "train epoch 258 / 1000 Done\n",
      "train epoch 259 / 1000 Done\n",
      "train epoch 260 / 1000 Done\n",
      "dev acc 0.56228375\n",
      "train loss 1.2764658\n",
      "train epoch 261 / 1000 Done\n",
      "train epoch 262 / 1000 Done\n",
      "train epoch 263 / 1000 Done\n",
      "train epoch 264 / 1000 Done\n",
      "train epoch 265 / 1000 Done\n",
      "dev acc 0.5648148\n",
      "train loss 1.2744067\n",
      "train epoch 266 / 1000 Done\n",
      "train epoch 267 / 1000 Done\n",
      "train epoch 268 / 1000 Done\n",
      "train epoch 269 / 1000 Done\n",
      "train epoch 270 / 1000 Done\n",
      "dev acc 0.5638857\n",
      "train loss 1.2750916\n",
      "train epoch 271 / 1000 Done\n",
      "train epoch 272 / 1000 Done\n",
      "train epoch 273 / 1000 Done\n",
      "train epoch 274 / 1000 Done\n",
      "train epoch 275 / 1000 Done\n",
      "dev acc 0.5629886\n",
      "train loss 1.2739831\n",
      "train epoch 276 / 1000 Done\n",
      "train epoch 277 / 1000 Done\n",
      "train epoch 278 / 1000 Done\n",
      "train epoch 279 / 1000 Done\n",
      "train epoch 280 / 1000 Done\n",
      "dev acc 0.5638536\n",
      "train loss 1.2758036\n",
      "train epoch 281 / 1000 Done\n",
      "train epoch 282 / 1000 Done\n",
      "train epoch 283 / 1000 Done\n",
      "train epoch 284 / 1000 Done\n",
      "train epoch 285 / 1000 Done\n",
      "dev acc 0.5643663\n",
      "train loss 1.2747049\n",
      "train epoch 286 / 1000 Done\n",
      "train epoch 287 / 1000 Done\n",
      "train epoch 288 / 1000 Done\n",
      "train epoch 289 / 1000 Done\n",
      "train epoch 290 / 1000 Done\n",
      "dev acc 0.565808\n",
      "train loss 1.2733407\n",
      "train epoch 291 / 1000 Done\n",
      "train epoch 292 / 1000 Done\n",
      "train epoch 293 / 1000 Done\n",
      "train epoch 294 / 1000 Done\n",
      "train epoch 295 / 1000 Done\n",
      "dev acc 0.5658721\n",
      "train loss 1.2719992\n",
      "train epoch 296 / 1000 Done\n",
      "train epoch 297 / 1000 Done\n",
      "train epoch 298 / 1000 Done\n",
      "train epoch 299 / 1000 Done\n",
      "train epoch 300 / 1000 Done\n",
      "dev acc 0.5667692\n",
      "train loss 1.2722242\n",
      "train epoch 301 / 1000 Done\n",
      "train epoch 302 / 1000 Done\n",
      "train epoch 303 / 1000 Done\n",
      "train epoch 304 / 1000 Done\n",
      "train epoch 305 / 1000 Done\n",
      "dev acc 0.56609637\n",
      "train loss 1.2709012\n",
      "train epoch 306 / 1000 Done\n",
      "train epoch 307 / 1000 Done\n",
      "train epoch 308 / 1000 Done\n",
      "train epoch 309 / 1000 Done\n",
      "train epoch 310 / 1000 Done\n",
      "dev acc 0.5666731\n",
      "train loss 1.270557\n",
      "train epoch 311 / 1000 Done\n",
      "train epoch 312 / 1000 Done\n",
      "train epoch 313 / 1000 Done\n",
      "train epoch 314 / 1000 Done\n",
      "train epoch 315 / 1000 Done\n",
      "dev acc 0.56590414\n",
      "train loss 1.2691545\n",
      "train epoch 316 / 1000 Done\n",
      "train epoch 317 / 1000 Done\n",
      "train epoch 318 / 1000 Done\n",
      "train epoch 319 / 1000 Done\n",
      "train epoch 320 / 1000 Done\n",
      "dev acc 0.5645905\n",
      "train loss 1.2712971\n",
      "train epoch 321 / 1000 Done\n",
      "train epoch 322 / 1000 Done\n",
      "train epoch 323 / 1000 Done\n",
      "train epoch 324 / 1000 Done\n",
      "train epoch 325 / 1000 Done\n",
      "dev acc 0.5654556\n",
      "train loss 1.2713029\n",
      "train epoch 326 / 1000 Done\n",
      "train epoch 327 / 1000 Done\n",
      "train epoch 328 / 1000 Done\n",
      "train epoch 329 / 1000 Done\n",
      "train epoch 330 / 1000 Done\n",
      "dev acc 0.5659682\n",
      "train loss 1.2709519\n",
      "train epoch 331 / 1000 Done\n",
      "train epoch 332 / 1000 Done\n",
      "train epoch 333 / 1000 Done\n",
      "train epoch 334 / 1000 Done\n",
      "train epoch 335 / 1000 Done\n",
      "dev acc 0.56757015\n",
      "train loss 1.2687316\n",
      "train epoch 336 / 1000 Done\n",
      "train epoch 337 / 1000 Done\n",
      "train epoch 338 / 1000 Done\n",
      "train epoch 339 / 1000 Done\n",
      "train epoch 340 / 1000 Done\n",
      "dev acc 0.5660323\n",
      "train loss 1.2678739\n",
      "train epoch 341 / 1000 Done\n",
      "train epoch 342 / 1000 Done\n",
      "train epoch 343 / 1000 Done\n",
      "train epoch 344 / 1000 Done\n",
      "train epoch 345 / 1000 Done\n",
      "dev acc 0.5667692\n",
      "train loss 1.2673346\n",
      "train epoch 346 / 1000 Done\n",
      "train epoch 347 / 1000 Done\n",
      "train epoch 348 / 1000 Done\n",
      "train epoch 349 / 1000 Done\n",
      "train epoch 350 / 1000 Done\n",
      "dev acc 0.5667372\n",
      "train loss 1.2674432\n",
      "train epoch 351 / 1000 Done\n",
      "train epoch 352 / 1000 Done\n",
      "train epoch 353 / 1000 Done\n",
      "train epoch 354 / 1000 Done\n",
      "train epoch 355 / 1000 Done\n",
      "dev acc 0.5677624\n",
      "train loss 1.2667358\n",
      "train epoch 356 / 1000 Done\n",
      "train epoch 357 / 1000 Done\n",
      "train epoch 358 / 1000 Done\n",
      "train epoch 359 / 1000 Done\n",
      "train epoch 360 / 1000 Done\n",
      "dev acc 0.5650711\n",
      "train loss 1.2686269\n",
      "train epoch 361 / 1000 Done\n",
      "train epoch 362 / 1000 Done\n",
      "train epoch 363 / 1000 Done\n",
      "train epoch 364 / 1000 Done\n",
      "train epoch 365 / 1000 Done\n",
      "dev acc 0.56641674\n",
      "train loss 1.2682595\n",
      "train epoch 366 / 1000 Done\n",
      "train epoch 367 / 1000 Done\n",
      "train epoch 368 / 1000 Done\n",
      "train epoch 369 / 1000 Done\n",
      "train epoch 370 / 1000 Done\n",
      "dev acc 0.56897986\n",
      "train loss 1.267093\n",
      "train epoch 371 / 1000 Done\n",
      "train epoch 372 / 1000 Done\n",
      "train epoch 373 / 1000 Done\n",
      "train epoch 374 / 1000 Done\n",
      "train epoch 375 / 1000 Done\n",
      "dev acc 0.56747407\n",
      "train loss 1.2651732\n",
      "train epoch 376 / 1000 Done\n",
      "train epoch 377 / 1000 Done\n",
      "train epoch 378 / 1000 Done\n",
      "train epoch 379 / 1000 Done\n",
      "train epoch 380 / 1000 Done\n",
      "dev acc 0.56936437\n",
      "train loss 1.2659998\n",
      "train epoch 381 / 1000 Done\n",
      "train epoch 382 / 1000 Done\n",
      "train epoch 383 / 1000 Done\n",
      "train epoch 384 / 1000 Done\n",
      "train epoch 385 / 1000 Done\n",
      "dev acc 0.5681789\n",
      "train loss 1.2646087\n",
      "train epoch 386 / 1000 Done\n",
      "train epoch 387 / 1000 Done\n",
      "train epoch 388 / 1000 Done\n",
      "train epoch 389 / 1000 Done\n",
      "train epoch 390 / 1000 Done\n",
      "dev acc 0.5692682\n",
      "train loss 1.2681736\n",
      "train epoch 391 / 1000 Done\n",
      "train epoch 392 / 1000 Done\n",
      "train epoch 393 / 1000 Done\n",
      "train epoch 394 / 1000 Done\n",
      "train epoch 395 / 1000 Done\n",
      "dev acc 0.5676663\n",
      "train loss 1.2655349\n",
      "train epoch 396 / 1000 Done\n",
      "train epoch 397 / 1000 Done\n",
      "train epoch 398 / 1000 Done\n",
      "train epoch 399 / 1000 Done\n",
      "train epoch 400 / 1000 Done\n",
      "dev acc 0.5645905\n",
      "train loss 1.2658803\n",
      "train epoch 401 / 1000 Done\n",
      "train epoch 402 / 1000 Done\n",
      "train epoch 403 / 1000 Done\n",
      "train epoch 404 / 1000 Done\n",
      "train epoch 405 / 1000 Done\n",
      "dev acc 0.56606436\n",
      "train loss 1.2661093\n",
      "train epoch 406 / 1000 Done\n",
      "train epoch 407 / 1000 Done\n",
      "train epoch 408 / 1000 Done\n",
      "train epoch 409 / 1000 Done\n",
      "train epoch 410 / 1000 Done\n",
      "dev acc 0.56801873\n",
      "train loss 1.2633293\n",
      "train epoch 411 / 1000 Done\n",
      "train epoch 412 / 1000 Done\n",
      "train epoch 413 / 1000 Done\n",
      "train epoch 414 / 1000 Done\n",
      "train epoch 415 / 1000 Done\n",
      "dev acc 0.56942844\n",
      "train loss 1.2639621\n",
      "train epoch 416 / 1000 Done\n",
      "train epoch 417 / 1000 Done\n",
      "train epoch 418 / 1000 Done\n",
      "train epoch 419 / 1000 Done\n",
      "train epoch 420 / 1000 Done\n",
      "dev acc 0.56705755\n",
      "train loss 1.2635242\n",
      "train epoch 421 / 1000 Done\n",
      "train epoch 422 / 1000 Done\n",
      "train epoch 423 / 1000 Done\n",
      "train epoch 424 / 1000 Done\n",
      "train epoch 425 / 1000 Done\n",
      "dev acc 0.56869155\n",
      "train loss 1.2653217\n",
      "train epoch 426 / 1000 Done\n",
      "train epoch 427 / 1000 Done\n",
      "train epoch 428 / 1000 Done\n",
      "train epoch 429 / 1000 Done\n",
      "train epoch 430 / 1000 Done\n",
      "dev acc 0.5676983\n",
      "train loss 1.2642782\n",
      "train epoch 431 / 1000 Done\n",
      "train epoch 432 / 1000 Done\n",
      "train epoch 433 / 1000 Done\n",
      "train epoch 434 / 1000 Done\n",
      "train epoch 435 / 1000 Done\n",
      "dev acc 0.5699731\n",
      "train loss 1.2629414\n",
      "train epoch 436 / 1000 Done\n",
      "train epoch 437 / 1000 Done\n",
      "train epoch 438 / 1000 Done\n",
      "train epoch 439 / 1000 Done\n",
      "train epoch 440 / 1000 Done\n",
      "dev acc 0.56641674\n",
      "train loss 1.2622149\n",
      "train epoch 441 / 1000 Done\n",
      "train epoch 442 / 1000 Done\n",
      "train epoch 443 / 1000 Done\n",
      "train epoch 444 / 1000 Done\n",
      "train epoch 445 / 1000 Done\n",
      "dev acc 0.56708956\n",
      "train loss 1.2616332\n",
      "train epoch 446 / 1000 Done\n",
      "train epoch 447 / 1000 Done\n",
      "train epoch 448 / 1000 Done\n",
      "train epoch 449 / 1000 Done\n",
      "train epoch 450 / 1000 Done\n",
      "dev acc 0.5665129\n",
      "train loss 1.2625115\n",
      "train epoch 451 / 1000 Done\n",
      "train epoch 452 / 1000 Done\n",
      "train epoch 453 / 1000 Done\n",
      "train epoch 454 / 1000 Done\n",
      "train epoch 455 / 1000 Done\n",
      "dev acc 0.5650711\n",
      "train loss 1.2629682\n",
      "train epoch 456 / 1000 Done\n",
      "train epoch 457 / 1000 Done\n",
      "train epoch 458 / 1000 Done\n",
      "train epoch 459 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 460 / 1000 Done\n",
      "dev acc 0.56715363\n",
      "train loss 1.259878\n",
      "train epoch 461 / 1000 Done\n",
      "train epoch 462 / 1000 Done\n",
      "train epoch 463 / 1000 Done\n",
      "train epoch 464 / 1000 Done\n",
      "train epoch 465 / 1000 Done\n",
      "dev acc 0.5695566\n",
      "train loss 1.2596384\n",
      "train epoch 466 / 1000 Done\n",
      "train epoch 467 / 1000 Done\n",
      "train epoch 468 / 1000 Done\n",
      "train epoch 469 / 1000 Done\n",
      "train epoch 470 / 1000 Done\n",
      "dev acc 0.56846726\n",
      "train loss 1.2591655\n",
      "train epoch 471 / 1000 Done\n",
      "train epoch 472 / 1000 Done\n",
      "train epoch 473 / 1000 Done\n",
      "train epoch 474 / 1000 Done\n",
      "train epoch 475 / 1000 Done\n",
      "dev acc 0.56683326\n",
      "train loss 1.2604071\n",
      "train epoch 476 / 1000 Done\n",
      "train epoch 477 / 1000 Done\n",
      "train epoch 478 / 1000 Done\n",
      "train epoch 479 / 1000 Done\n",
      "train epoch 480 / 1000 Done\n",
      "dev acc 0.5684032\n",
      "train loss 1.2597601\n",
      "train epoch 481 / 1000 Done\n",
      "train epoch 482 / 1000 Done\n",
      "train epoch 483 / 1000 Done\n",
      "train epoch 484 / 1000 Done\n",
      "train epoch 485 / 1000 Done\n",
      "dev acc 0.56635267\n",
      "train loss 1.2605032\n",
      "train epoch 486 / 1000 Done\n",
      "train epoch 487 / 1000 Done\n",
      "train epoch 488 / 1000 Done\n",
      "train epoch 489 / 1000 Done\n",
      "train epoch 490 / 1000 Done\n",
      "dev acc 0.5680828\n",
      "train loss 1.2584075\n",
      "train epoch 491 / 1000 Done\n",
      "train epoch 492 / 1000 Done\n",
      "train epoch 493 / 1000 Done\n",
      "train epoch 494 / 1000 Done\n",
      "train epoch 495 / 1000 Done\n",
      "dev acc 0.56897986\n",
      "train loss 1.2598764\n",
      "train epoch 496 / 1000 Done\n",
      "train epoch 497 / 1000 Done\n",
      "train epoch 498 / 1000 Done\n",
      "train epoch 499 / 1000 Done\n",
      "train epoch 500 / 1000 Done\n",
      "dev acc 0.5686275\n",
      "train loss 1.2590723\n",
      "train epoch 501 / 1000 Done\n",
      "train epoch 502 / 1000 Done\n",
      "train epoch 503 / 1000 Done\n",
      "train epoch 504 / 1000 Done\n",
      "train epoch 505 / 1000 Done\n",
      "dev acc 0.5692682\n",
      "train loss 1.2577496\n",
      "train epoch 506 / 1000 Done\n",
      "train epoch 507 / 1000 Done\n",
      "train epoch 508 / 1000 Done\n",
      "train epoch 509 / 1000 Done\n",
      "train epoch 510 / 1000 Done\n",
      "dev acc 0.5692682\n",
      "train loss 1.257966\n",
      "train epoch 511 / 1000 Done\n",
      "train epoch 512 / 1000 Done\n",
      "train epoch 513 / 1000 Done\n",
      "train epoch 514 / 1000 Done\n",
      "train epoch 515 / 1000 Done\n",
      "dev acc 0.5685954\n",
      "train loss 1.2576416\n",
      "train epoch 516 / 1000 Done\n",
      "train epoch 517 / 1000 Done\n",
      "train epoch 518 / 1000 Done\n",
      "train epoch 519 / 1000 Done\n",
      "train epoch 520 / 1000 Done\n",
      "dev acc 0.5683711\n",
      "train loss 1.258555\n",
      "train epoch 521 / 1000 Done\n",
      "train epoch 522 / 1000 Done\n",
      "train epoch 523 / 1000 Done\n",
      "train epoch 524 / 1000 Done\n",
      "train epoch 525 / 1000 Done\n",
      "dev acc 0.5697488\n",
      "train loss 1.2567309\n",
      "train epoch 526 / 1000 Done\n",
      "train epoch 527 / 1000 Done\n",
      "train epoch 528 / 1000 Done\n",
      "train epoch 529 / 1000 Done\n",
      "train epoch 530 / 1000 Done\n",
      "dev acc 0.5681469\n",
      "train loss 1.2577051\n",
      "train epoch 531 / 1000 Done\n",
      "train epoch 532 / 1000 Done\n",
      "train epoch 533 / 1000 Done\n",
      "train epoch 534 / 1000 Done\n",
      "train epoch 535 / 1000 Done\n",
      "dev acc 0.56962067\n",
      "train loss 1.2575859\n",
      "train epoch 536 / 1000 Done\n",
      "train epoch 537 / 1000 Done\n",
      "train epoch 538 / 1000 Done\n",
      "train epoch 539 / 1000 Done\n",
      "train epoch 540 / 1000 Done\n",
      "dev acc 0.57061386\n",
      "train loss 1.2566154\n",
      "train epoch 541 / 1000 Done\n",
      "train epoch 542 / 1000 Done\n",
      "train epoch 543 / 1000 Done\n",
      "train epoch 544 / 1000 Done\n",
      "train epoch 545 / 1000 Done\n",
      "dev acc 0.5697808\n",
      "train loss 1.2568079\n",
      "train epoch 546 / 1000 Done\n",
      "train epoch 547 / 1000 Done\n",
      "train epoch 548 / 1000 Done\n",
      "train epoch 549 / 1000 Done\n",
      "train epoch 550 / 1000 Done\n",
      "dev acc 0.5711585\n",
      "train loss 1.2559762\n",
      "train epoch 551 / 1000 Done\n",
      "train epoch 552 / 1000 Done\n",
      "train epoch 553 / 1000 Done\n",
      "train epoch 554 / 1000 Done\n",
      "train epoch 555 / 1000 Done\n",
      "dev acc 0.5702935\n",
      "train loss 1.2572265\n",
      "train epoch 556 / 1000 Done\n",
      "train epoch 557 / 1000 Done\n",
      "train epoch 558 / 1000 Done\n",
      "train epoch 559 / 1000 Done\n",
      "train epoch 560 / 1000 Done\n",
      "dev acc 0.5705178\n",
      "train loss 1.2564917\n",
      "train epoch 561 / 1000 Done\n",
      "train epoch 562 / 1000 Done\n",
      "train epoch 563 / 1000 Done\n",
      "train epoch 564 / 1000 Done\n",
      "train epoch 565 / 1000 Done\n",
      "dev acc 0.5704857\n",
      "train loss 1.2560185\n",
      "train epoch 566 / 1000 Done\n",
      "train epoch 567 / 1000 Done\n",
      "train epoch 568 / 1000 Done\n",
      "train epoch 569 / 1000 Done\n",
      "train epoch 570 / 1000 Done\n",
      "dev acc 0.5709022\n",
      "train loss 1.2561802\n",
      "train epoch 571 / 1000 Done\n",
      "train epoch 572 / 1000 Done\n",
      "train epoch 573 / 1000 Done\n",
      "train epoch 574 / 1000 Done\n",
      "train epoch 575 / 1000 Done\n",
      "dev acc 0.5686275\n",
      "train loss 1.2550943\n",
      "train epoch 576 / 1000 Done\n",
      "train epoch 577 / 1000 Done\n",
      "train epoch 578 / 1000 Done\n",
      "train epoch 579 / 1000 Done\n",
      "train epoch 580 / 1000 Done\n",
      "dev acc 0.56987697\n",
      "train loss 1.2545687\n",
      "train epoch 581 / 1000 Done\n",
      "train epoch 582 / 1000 Done\n",
      "train epoch 583 / 1000 Done\n",
      "train epoch 584 / 1000 Done\n",
      "train epoch 585 / 1000 Done\n",
      "dev acc 0.5690119\n",
      "train loss 1.2572633\n",
      "train epoch 586 / 1000 Done\n",
      "train epoch 587 / 1000 Done\n",
      "train epoch 588 / 1000 Done\n",
      "train epoch 589 / 1000 Done\n",
      "train epoch 590 / 1000 Done\n",
      "dev acc 0.5697488\n",
      "train loss 1.2542646\n",
      "train epoch 591 / 1000 Done\n",
      "train epoch 592 / 1000 Done\n",
      "train epoch 593 / 1000 Done\n",
      "train epoch 594 / 1000 Done\n",
      "train epoch 595 / 1000 Done\n",
      "dev acc 0.5721838\n",
      "train loss 1.2540194\n",
      "train epoch 596 / 1000 Done\n",
      "train epoch 597 / 1000 Done\n",
      "train epoch 598 / 1000 Done\n",
      "train epoch 599 / 1000 Done\n",
      "train epoch 600 / 1000 Done\n",
      "dev acc 0.5721517\n",
      "train loss 1.2558246\n",
      "train epoch 601 / 1000 Done\n",
      "train epoch 602 / 1000 Done\n",
      "train epoch 603 / 1000 Done\n",
      "train epoch 604 / 1000 Done\n",
      "train epoch 605 / 1000 Done\n",
      "dev acc 0.5718954\n",
      "train loss 1.2545673\n",
      "train epoch 606 / 1000 Done\n",
      "train epoch 607 / 1000 Done\n",
      "train epoch 608 / 1000 Done\n",
      "train epoch 609 / 1000 Done\n",
      "train epoch 610 / 1000 Done\n",
      "dev acc 0.570742\n",
      "train loss 1.2528543\n",
      "train epoch 611 / 1000 Done\n",
      "train epoch 612 / 1000 Done\n",
      "train epoch 613 / 1000 Done\n",
      "train epoch 614 / 1000 Done\n",
      "train epoch 615 / 1000 Done\n",
      "dev acc 0.56942844\n",
      "train loss 1.2544682\n",
      "train epoch 616 / 1000 Done\n",
      "train epoch 617 / 1000 Done\n",
      "train epoch 618 / 1000 Done\n",
      "train epoch 619 / 1000 Done\n",
      "train epoch 620 / 1000 Done\n",
      "dev acc 0.5711906\n",
      "train loss 1.2524788\n",
      "train epoch 621 / 1000 Done\n",
      "train epoch 622 / 1000 Done\n",
      "train epoch 623 / 1000 Done\n",
      "train epoch 624 / 1000 Done\n",
      "train epoch 625 / 1000 Done\n",
      "dev acc 0.57131875\n",
      "train loss 1.253712\n",
      "train epoch 626 / 1000 Done\n",
      "train epoch 627 / 1000 Done\n",
      "train epoch 628 / 1000 Done\n",
      "train epoch 629 / 1000 Done\n",
      "train epoch 630 / 1000 Done\n",
      "dev acc 0.56994104\n",
      "train loss 1.2536396\n",
      "train epoch 631 / 1000 Done\n",
      "train epoch 632 / 1000 Done\n",
      "train epoch 633 / 1000 Done\n",
      "train epoch 634 / 1000 Done\n",
      "train epoch 635 / 1000 Done\n",
      "dev acc 0.5708061\n",
      "train loss 1.2508187\n",
      "train epoch 636 / 1000 Done\n",
      "train epoch 637 / 1000 Done\n",
      "train epoch 638 / 1000 Done\n",
      "train epoch 639 / 1000 Done\n",
      "train epoch 640 / 1000 Done\n",
      "dev acc 0.57058185\n",
      "train loss 1.2532467\n",
      "train epoch 641 / 1000 Done\n",
      "train epoch 642 / 1000 Done\n",
      "train epoch 643 / 1000 Done\n",
      "train epoch 644 / 1000 Done\n",
      "train epoch 645 / 1000 Done\n",
      "dev acc 0.5713828\n",
      "train loss 1.254491\n",
      "train epoch 646 / 1000 Done\n",
      "train epoch 647 / 1000 Done\n",
      "train epoch 648 / 1000 Done\n",
      "train epoch 649 / 1000 Done\n",
      "train epoch 650 / 1000 Done\n",
      "dev acc 0.57019734\n",
      "train loss 1.2520269\n",
      "train epoch 651 / 1000 Done\n",
      "train epoch 652 / 1000 Done\n",
      "train epoch 653 / 1000 Done\n",
      "train epoch 654 / 1000 Done\n",
      "train epoch 655 / 1000 Done\n",
      "dev acc 0.57045364\n",
      "train loss 1.2514694\n",
      "train epoch 656 / 1000 Done\n",
      "train epoch 657 / 1000 Done\n",
      "train epoch 658 / 1000 Done\n",
      "train epoch 659 / 1000 Done\n",
      "train epoch 660 / 1000 Done\n",
      "dev acc 0.57282454\n",
      "train loss 1.252421\n",
      "train epoch 661 / 1000 Done\n",
      "train epoch 662 / 1000 Done\n",
      "train epoch 663 / 1000 Done\n",
      "train epoch 664 / 1000 Done\n",
      "train epoch 665 / 1000 Done\n",
      "dev acc 0.5712547\n",
      "train loss 1.2507765\n",
      "train epoch 666 / 1000 Done\n",
      "train epoch 667 / 1000 Done\n",
      "train epoch 668 / 1000 Done\n",
      "train epoch 669 / 1000 Done\n",
      "train epoch 670 / 1000 Done\n",
      "dev acc 0.5735294\n",
      "train loss 1.2515137\n",
      "train epoch 671 / 1000 Done\n",
      "train epoch 672 / 1000 Done\n",
      "train epoch 673 / 1000 Done\n",
      "train epoch 674 / 1000 Done\n",
      "train epoch 675 / 1000 Done\n",
      "dev acc 0.57208765\n",
      "train loss 1.2509608\n",
      "train epoch 676 / 1000 Done\n",
      "train epoch 677 / 1000 Done\n",
      "train epoch 678 / 1000 Done\n",
      "train epoch 679 / 1000 Done\n",
      "train epoch 680 / 1000 Done\n",
      "dev acc 0.5731129\n",
      "train loss 1.2521137\n",
      "train epoch 681 / 1000 Done\n",
      "train epoch 682 / 1000 Done\n",
      "train epoch 683 / 1000 Done\n",
      "train epoch 684 / 1000 Done\n",
      "train epoch 685 / 1000 Done\n",
      "dev acc 0.57109445\n",
      "train loss 1.2516055\n",
      "train epoch 686 / 1000 Done\n",
      "train epoch 687 / 1000 Done\n",
      "train epoch 688 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 689 / 1000 Done\n",
      "train epoch 690 / 1000 Done\n",
      "dev acc 0.57067794\n",
      "train loss 1.2511585\n",
      "train epoch 691 / 1000 Done\n",
      "train epoch 692 / 1000 Done\n",
      "train epoch 693 / 1000 Done\n",
      "train epoch 694 / 1000 Done\n",
      "train epoch 695 / 1000 Done\n",
      "dev acc 0.5721197\n",
      "train loss 1.2502112\n",
      "train epoch 696 / 1000 Done\n",
      "train epoch 697 / 1000 Done\n",
      "train epoch 698 / 1000 Done\n",
      "train epoch 699 / 1000 Done\n",
      "train epoch 700 / 1000 Done\n",
      "dev acc 0.57071\n",
      "train loss 1.2494948\n",
      "train epoch 701 / 1000 Done\n",
      "train epoch 702 / 1000 Done\n",
      "train epoch 703 / 1000 Done\n",
      "train epoch 704 / 1000 Done\n",
      "train epoch 705 / 1000 Done\n",
      "dev acc 0.571511\n",
      "train loss 1.2482859\n",
      "train epoch 706 / 1000 Done\n",
      "train epoch 707 / 1000 Done\n",
      "train epoch 708 / 1000 Done\n",
      "train epoch 709 / 1000 Done\n",
      "train epoch 710 / 1000 Done\n",
      "dev acc 0.5711585\n",
      "train loss 1.249132\n",
      "train epoch 711 / 1000 Done\n",
      "train epoch 712 / 1000 Done\n",
      "train epoch 713 / 1000 Done\n",
      "train epoch 714 / 1000 Done\n",
      "train epoch 715 / 1000 Done\n",
      "dev acc 0.5747789\n",
      "train loss 1.249066\n",
      "train epoch 716 / 1000 Done\n",
      "train epoch 717 / 1000 Done\n",
      "train epoch 718 / 1000 Done\n",
      "train epoch 719 / 1000 Done\n",
      "train epoch 720 / 1000 Done\n",
      "dev acc 0.5721517\n",
      "train loss 1.2518005\n",
      "train epoch 721 / 1000 Done\n",
      "train epoch 722 / 1000 Done\n",
      "train epoch 723 / 1000 Done\n",
      "train epoch 724 / 1000 Done\n",
      "train epoch 725 / 1000 Done\n",
      "dev acc 0.57199156\n",
      "train loss 1.2495769\n",
      "train epoch 726 / 1000 Done\n",
      "train epoch 727 / 1000 Done\n",
      "train epoch 728 / 1000 Done\n",
      "train epoch 729 / 1000 Done\n",
      "train epoch 730 / 1000 Done\n",
      "dev acc 0.57272846\n",
      "train loss 1.2502187\n",
      "train epoch 731 / 1000 Done\n",
      "train epoch 732 / 1000 Done\n",
      "train epoch 733 / 1000 Done\n",
      "train epoch 734 / 1000 Done\n",
      "train epoch 735 / 1000 Done\n",
      "dev acc 0.57282454\n",
      "train loss 1.2478002\n",
      "train epoch 736 / 1000 Done\n",
      "train epoch 737 / 1000 Done\n",
      "train epoch 738 / 1000 Done\n",
      "train epoch 739 / 1000 Done\n",
      "train epoch 740 / 1000 Done\n",
      "dev acc 0.57199156\n",
      "train loss 1.2484362\n",
      "train epoch 741 / 1000 Done\n",
      "train epoch 742 / 1000 Done\n",
      "train epoch 743 / 1000 Done\n",
      "train epoch 744 / 1000 Done\n",
      "train epoch 745 / 1000 Done\n",
      "dev acc 0.573177\n",
      "train loss 1.2491696\n",
      "train epoch 746 / 1000 Done\n",
      "train epoch 747 / 1000 Done\n",
      "train epoch 748 / 1000 Done\n",
      "train epoch 749 / 1000 Done\n",
      "train epoch 750 / 1000 Done\n",
      "dev acc 0.57282454\n",
      "train loss 1.2478738\n",
      "train epoch 751 / 1000 Done\n",
      "train epoch 752 / 1000 Done\n",
      "train epoch 753 / 1000 Done\n",
      "train epoch 754 / 1000 Done\n",
      "train epoch 755 / 1000 Done\n",
      "dev acc 0.5732731\n",
      "train loss 1.2453163\n",
      "train epoch 756 / 1000 Done\n",
      "train epoch 757 / 1000 Done\n",
      "train epoch 758 / 1000 Done\n",
      "train epoch 759 / 1000 Done\n",
      "train epoch 760 / 1000 Done\n",
      "dev acc 0.57256824\n",
      "train loss 1.2484148\n",
      "train epoch 761 / 1000 Done\n",
      "train epoch 762 / 1000 Done\n",
      "train epoch 763 / 1000 Done\n",
      "train epoch 764 / 1000 Done\n",
      "train epoch 765 / 1000 Done\n",
      "dev acc 0.57308084\n",
      "train loss 1.2485198\n",
      "train epoch 766 / 1000 Done\n",
      "train epoch 767 / 1000 Done\n",
      "train epoch 768 / 1000 Done\n",
      "train epoch 769 / 1000 Done\n",
      "train epoch 770 / 1000 Done\n",
      "dev acc 0.57394594\n",
      "train loss 1.2458208\n",
      "train epoch 771 / 1000 Done\n",
      "train epoch 772 / 1000 Done\n",
      "train epoch 773 / 1000 Done\n",
      "train epoch 774 / 1000 Done\n",
      "train epoch 775 / 1000 Done\n",
      "dev acc 0.57308084\n",
      "train loss 1.2469876\n",
      "train epoch 776 / 1000 Done\n",
      "train epoch 777 / 1000 Done\n",
      "train epoch 778 / 1000 Done\n",
      "train epoch 779 / 1000 Done\n",
      "train epoch 780 / 1000 Done\n",
      "dev acc 0.57413816\n",
      "train loss 1.2499102\n",
      "train epoch 781 / 1000 Done\n",
      "train epoch 782 / 1000 Done\n",
      "train epoch 783 / 1000 Done\n",
      "train epoch 784 / 1000 Done\n",
      "train epoch 785 / 1000 Done\n",
      "dev acc 0.5752275\n",
      "train loss 1.2493668\n",
      "train epoch 786 / 1000 Done\n",
      "train epoch 787 / 1000 Done\n",
      "train epoch 788 / 1000 Done\n",
      "train epoch 789 / 1000 Done\n",
      "train epoch 790 / 1000 Done\n",
      "dev acc 0.5752916\n",
      "train loss 1.2469063\n",
      "train epoch 791 / 1000 Done\n",
      "train epoch 792 / 1000 Done\n",
      "train epoch 793 / 1000 Done\n",
      "train epoch 794 / 1000 Done\n",
      "train epoch 795 / 1000 Done\n",
      "dev acc 0.57397795\n",
      "train loss 1.245602\n",
      "train epoch 796 / 1000 Done\n",
      "train epoch 797 / 1000 Done\n",
      "train epoch 798 / 1000 Done\n",
      "train epoch 799 / 1000 Done\n",
      "train epoch 800 / 1000 Done\n",
      "dev acc 0.57330513\n",
      "train loss 1.2449836\n",
      "train epoch 801 / 1000 Done\n",
      "train epoch 802 / 1000 Done\n",
      "train epoch 803 / 1000 Done\n",
      "train epoch 804 / 1000 Done\n",
      "train epoch 805 / 1000 Done\n",
      "dev acc 0.57308084\n",
      "train loss 1.2472575\n",
      "train epoch 806 / 1000 Done\n",
      "train epoch 807 / 1000 Done\n",
      "train epoch 808 / 1000 Done\n",
      "train epoch 809 / 1000 Done\n",
      "train epoch 810 / 1000 Done\n",
      "dev acc 0.5737857\n",
      "train loss 1.2470877\n",
      "train epoch 811 / 1000 Done\n",
      "train epoch 812 / 1000 Done\n",
      "train epoch 813 / 1000 Done\n",
      "train epoch 814 / 1000 Done\n",
      "train epoch 815 / 1000 Done\n",
      "dev acc 0.5755479\n",
      "train loss 1.2464086\n",
      "train epoch 816 / 1000 Done\n",
      "train epoch 817 / 1000 Done\n",
      "train epoch 818 / 1000 Done\n",
      "train epoch 819 / 1000 Done\n",
      "train epoch 820 / 1000 Done\n",
      "dev acc 0.5755479\n",
      "train loss 1.244759\n",
      "train epoch 821 / 1000 Done\n",
      "train epoch 822 / 1000 Done\n",
      "train epoch 823 / 1000 Done\n",
      "train epoch 824 / 1000 Done\n",
      "train epoch 825 / 1000 Done\n",
      "dev acc 0.57330513\n",
      "train loss 1.2463188\n",
      "train epoch 826 / 1000 Done\n",
      "train epoch 827 / 1000 Done\n",
      "train epoch 828 / 1000 Done\n",
      "train epoch 829 / 1000 Done\n",
      "train epoch 830 / 1000 Done\n",
      "dev acc 0.57545173\n",
      "train loss 1.2479527\n",
      "train epoch 831 / 1000 Done\n",
      "train epoch 832 / 1000 Done\n",
      "train epoch 833 / 1000 Done\n",
      "train epoch 834 / 1000 Done\n",
      "train epoch 835 / 1000 Done\n",
      "dev acc 0.5750032\n",
      "train loss 1.246531\n",
      "train epoch 836 / 1000 Done\n",
      "train epoch 837 / 1000 Done\n",
      "train epoch 838 / 1000 Done\n",
      "train epoch 839 / 1000 Done\n",
      "train epoch 840 / 1000 Done\n",
      "dev acc 0.574811\n",
      "train loss 1.2468597\n",
      "train epoch 841 / 1000 Done\n",
      "train epoch 842 / 1000 Done\n",
      "train epoch 843 / 1000 Done\n",
      "train epoch 844 / 1000 Done\n",
      "train epoch 845 / 1000 Done\n",
      "dev acc 0.5742983\n",
      "train loss 1.2432736\n",
      "train epoch 846 / 1000 Done\n",
      "train epoch 847 / 1000 Done\n",
      "train epoch 848 / 1000 Done\n",
      "train epoch 849 / 1000 Done\n",
      "train epoch 850 / 1000 Done\n",
      "dev acc 0.5763809\n",
      "train loss 1.2451127\n",
      "train epoch 851 / 1000 Done\n",
      "train epoch 852 / 1000 Done\n",
      "train epoch 853 / 1000 Done\n",
      "train epoch 854 / 1000 Done\n",
      "train epoch 855 / 1000 Done\n",
      "dev acc 0.5752595\n",
      "train loss 1.2435355\n",
      "train epoch 856 / 1000 Done\n",
      "train epoch 857 / 1000 Done\n",
      "train epoch 858 / 1000 Done\n",
      "train epoch 859 / 1000 Done\n",
      "train epoch 860 / 1000 Done\n",
      "dev acc 0.5737857\n",
      "train loss 1.243803\n",
      "train epoch 861 / 1000 Done\n",
      "train epoch 862 / 1000 Done\n",
      "train epoch 863 / 1000 Done\n",
      "train epoch 864 / 1000 Done\n",
      "train epoch 865 / 1000 Done\n",
      "dev acc 0.57346535\n",
      "train loss 1.2432703\n",
      "train epoch 866 / 1000 Done\n",
      "train epoch 867 / 1000 Done\n",
      "train epoch 868 / 1000 Done\n",
      "train epoch 869 / 1000 Done\n",
      "train epoch 870 / 1000 Done\n",
      "dev acc 0.5747469\n",
      "train loss 1.2442768\n",
      "train epoch 871 / 1000 Done\n",
      "train epoch 872 / 1000 Done\n",
      "train epoch 873 / 1000 Done\n",
      "train epoch 874 / 1000 Done\n",
      "train epoch 875 / 1000 Done\n",
      "dev acc 0.5743304\n",
      "train loss 1.2434282\n",
      "train epoch 876 / 1000 Done\n",
      "train epoch 877 / 1000 Done\n",
      "train epoch 878 / 1000 Done\n",
      "train epoch 879 / 1000 Done\n",
      "train epoch 880 / 1000 Done\n",
      "dev acc 0.57401\n",
      "train loss 1.244515\n",
      "train epoch 881 / 1000 Done\n",
      "train epoch 882 / 1000 Done\n",
      "train epoch 883 / 1000 Done\n",
      "train epoch 884 / 1000 Done\n",
      "train epoch 885 / 1000 Done\n",
      "dev acc 0.5743304\n",
      "train loss 1.2438546\n",
      "train epoch 886 / 1000 Done\n",
      "train epoch 887 / 1000 Done\n",
      "train epoch 888 / 1000 Done\n",
      "train epoch 889 / 1000 Done\n",
      "train epoch 890 / 1000 Done\n",
      "dev acc 0.57330513\n",
      "train loss 1.2456697\n",
      "train epoch 891 / 1000 Done\n",
      "train epoch 892 / 1000 Done\n",
      "train epoch 893 / 1000 Done\n",
      "train epoch 894 / 1000 Done\n",
      "train epoch 895 / 1000 Done\n",
      "dev acc 0.57205564\n",
      "train loss 1.2435448\n",
      "train epoch 896 / 1000 Done\n",
      "train epoch 897 / 1000 Done\n",
      "train epoch 898 / 1000 Done\n",
      "train epoch 899 / 1000 Done\n",
      "train epoch 900 / 1000 Done\n",
      "dev acc 0.57439446\n",
      "train loss 1.245772\n",
      "train epoch 901 / 1000 Done\n",
      "train epoch 902 / 1000 Done\n",
      "train epoch 903 / 1000 Done\n",
      "train epoch 904 / 1000 Done\n",
      "train epoch 905 / 1000 Done\n",
      "dev acc 0.5736896\n",
      "train loss 1.2440277\n",
      "train epoch 906 / 1000 Done\n",
      "train epoch 907 / 1000 Done\n",
      "train epoch 908 / 1000 Done\n",
      "train epoch 909 / 1000 Done\n",
      "train epoch 910 / 1000 Done\n",
      "dev acc 0.57413816\n",
      "train loss 1.2417353\n",
      "train epoch 911 / 1000 Done\n",
      "train epoch 912 / 1000 Done\n",
      "train epoch 913 / 1000 Done\n",
      "train epoch 914 / 1000 Done\n",
      "train epoch 915 / 1000 Done\n",
      "dev acc 0.574042\n",
      "train loss 1.240957\n",
      "train epoch 916 / 1000 Done\n",
      "train epoch 917 / 1000 Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 918 / 1000 Done\n",
      "train epoch 919 / 1000 Done\n",
      "train epoch 920 / 1000 Done\n",
      "dev acc 0.57487506\n",
      "train loss 1.2457948\n",
      "train epoch 921 / 1000 Done\n",
      "train epoch 922 / 1000 Done\n",
      "train epoch 923 / 1000 Done\n",
      "train epoch 924 / 1000 Done\n",
      "train epoch 925 / 1000 Done\n",
      "dev acc 0.5735935\n",
      "train loss 1.2446873\n",
      "train epoch 926 / 1000 Done\n",
      "train epoch 927 / 1000 Done\n",
      "train epoch 928 / 1000 Done\n",
      "train epoch 929 / 1000 Done\n",
      "train epoch 930 / 1000 Done\n",
      "dev acc 0.5741702\n",
      "train loss 1.2441809\n",
      "train epoch 931 / 1000 Done\n",
      "train epoch 932 / 1000 Done\n",
      "train epoch 933 / 1000 Done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d4e70c339da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d4e70c339da9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_dropout_keep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_drop_out_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     }\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train epoch %d / %d Done'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu-tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from datetime import datetime\n",
    "\n",
    "class CNNLSTM:\n",
    "    def __init__(self, seq_len, num_classes, batch_seqs_num, embedding_matrix, embedding_size, filter_sizes,\n",
    "                num_filters, conv_activate_fn = tf.nn.relu, fcl_activate_fn = tf.sigmoid, learning_rate = 0.01,\n",
    "                n_epochs = 100, filtered_dims = 128, pooled_dims = 100, num_lstm_cells = 1, lstm_hiden_size = 32,\n",
    "                cnn_drop_out_prob = 0.5, lstm_drop_out_prob = 0.5, sum_root_dir = \"tf_logs\"):\n",
    "        self.seq_len = seq_len\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_seqs_num = batch_seqs_num\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_size = embedding_size\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.conv_activate_fn = conv_activate_fn\n",
    "        self.fcl_activate_fn = fcl_activate_fn\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.filtered_dims = filtered_dims\n",
    "        self.pooled_dims = pooled_dims\n",
    "        if(filtered_dims > embedding_size):\n",
    "            print('filtered_dims should be less than embedding_size')\n",
    "        self.num_lstm_cells = num_lstm_cells\n",
    "        self.lstm_hiden_size = lstm_hiden_size\n",
    "        self.cnn_drop_out_prob = cnn_drop_out_prob\n",
    "        self.lstm_drop_out_prob = lstm_drop_out_prob\n",
    "        self.log_dir = self.log_dir(sum_root_dir)\n",
    "        self.graph = tf.Graph()\n",
    "    \n",
    "    def log_dir(self, root_logdir):\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "        log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "        return log_dir\n",
    "    \n",
    "    def build(self):\n",
    "        with tf.name_scope(\"cnn_lstm\"), self.graph.as_default():\n",
    "            self.input_x = tf.placeholder(dtype = tf.int32, shape = [None, self.seq_len], name = \"input_x\")\n",
    "            self.input_y = tf.placeholder(dtype = tf.int32, shape = [None, self.num_classes], name = \"input_y\")\n",
    "            self.cnn_dropout_keep_prob = tf.placeholder(tf.float32, name=\"cnn_dropout_keep_prob\")\n",
    "            self.lstm_dropout_keep_prob = tf.placeholder(tf.float32, name=\"lstm_dropout_keep_prob\")\n",
    "            self.global_step = tf.Variable(0, trainable = False)\n",
    "\n",
    "            with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "                self.embedding_matrix = tf.constant(self.embedding_matrix, name = \"embedding_matrix\", dtype = tf.float32)\n",
    "                self.embedded = tf.expand_dims(tf.nn.embedding_lookup(self.embedding_matrix, self.input_x), -1,\n",
    "                                               name = \"embedded_output\")\n",
    "            self.pooled_outputs = []\n",
    "            filter_size = self.filter_sizes[0]\n",
    "            with tf.name_scope(\"conv_maxpool\"):\n",
    "                filter_shape = [filter_size, self.embedding_size - self.filtered_dims + 1, 1, self.num_filters]\n",
    "                filter_weight = tf.Variable(tf.truncated_normal(filter_shape, -1, 1), name = \"filter_weight\")\n",
    "                filter_bias = tf.Variable(tf.truncated_normal([self.num_filters], -1, 1))\n",
    "                conv_output = self.conv_activate_fn(tf.nn.bias_add(tf.nn.conv2d(\n",
    "                    self.embedded,\n",
    "                    filter_weight,\n",
    "                    strides = [1, 1, 1, 1],\n",
    "                    padding = 'VALID',\n",
    "                ), filter_bias, name = \"conv_output\"), name = \"act_conv_output\")\n",
    "\n",
    "                pooled_output = tf.nn.max_pool(conv_output,\n",
    "                                              ksize = [1, 1, self.filtered_dims - self.pooled_dims + 1, 1],\n",
    "                                              strides = [1, 1, 1, 1],\n",
    "                                              padding = \"VALID\",\n",
    "                                              name = \"pooled_output\")\n",
    "                self.reduced_pooled_output = tf.reshape(pooled_output, [-1, pooled_output.shape[1],\n",
    "                                                                            (self.pooled_dims) * self.num_filters],\n",
    "                                                       name = 'reduced_pooled_output')\n",
    "            with tf.name_scope(\"cnn_dropout\"):\n",
    "                self.droped_pooled_output = tf.nn.dropout(self.reduced_pooled_output, self.cnn_dropout_keep_prob)\n",
    "            with tf.name_scope(\"lstm\"):\n",
    "                self.lstm_cells = [tf.nn.rnn_cell.BasicLSTMCell(self.lstm_hiden_size, name = \"%s%d\" % ('lstmcell_', i)) \n",
    "                                  for i in range(self.num_lstm_cells)]\n",
    "                self.cells = tf.nn.rnn_cell.MultiRNNCell(self.lstm_cells)\n",
    "                self.initial_state = self.cells.zero_state(self.batch_seqs_num, tf.float32)\n",
    "                self.lstm_output, self.lstm_state = tf.nn.dynamic_rnn(self.cells, self.droped_pooled_output, \n",
    "                                                                     dtype = tf.float32)\n",
    "                self.lstm_last_output = self.lstm_state[-1].h\n",
    "            with tf.name_scope(\"lstm_dropout\"):\n",
    "                self.droped_lstm_output = tf.nn.dropout(self.lstm_last_output, self.lstm_dropout_keep_prob)\n",
    "            with tf.name_scope(\"full_connect\"):\n",
    "                self.fcl_output = tf.contrib.layers.fully_connected(self.droped_lstm_output, \n",
    "                                                              self.num_classes,\n",
    "                                                              self.fcl_activate_fn)\n",
    "            self.prediction = self.fcl_output\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits = self.prediction, labels = self.input_y,  \n",
    "                ))\n",
    "            with tf.name_scope(\"target\"):\n",
    "                self.train_correct = tf.equal(tf.arg_max(self.prediction, 1), tf.arg_max(self.input_y, 1), name = \"correct\")\n",
    "                self.train_acc = tf.reduce_mean(tf.cast(self.train_correct, tf.float32), name = \"acc\")\n",
    "            with tf.name_scope(\"summary\"):\n",
    "                self.loss_sum = tf.summary.scalar(\"loss\", self.loss)\n",
    "                self.acc_sum = tf.summary.scalar(\"acc\", self.train_acc)\n",
    "                self.sum = tf.summary.merge_all()\n",
    "                self.filewriter = tf.summary.FileWriter(self.log_dir, tf.get_default_graph())\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            self.train_step = self.optimizer.minimize(self.loss, global_step = self.global_step)\n",
    "            \n",
    "    \n",
    "    def fit(self, x, y, dev_x = None, dev_y = None, test_x = None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.dev_x = dev_x\n",
    "        self.dev_y = dev_y\n",
    "        self.test_x = test_x\n",
    "    \n",
    "    def train(self):\n",
    "        print('tf log dir : ', self.log_dir)\n",
    "        n_batches = int(np.ceil(len(self.x) / self.batch_seqs_num))\n",
    "        batch_size = self.batch_seqs_num\n",
    "        dev_feed_dict = {\n",
    "            self.input_x : self.dev_x,\n",
    "            self.input_y : self.dev_y,\n",
    "            self.cnn_dropout_keep_prob : 1.0,\n",
    "            self.lstm_dropout_keep_prob : 1.0\n",
    "        }\n",
    "        train_feed_dict = {\n",
    "            self.input_x : self.x[:10000],\n",
    "            self.input_y : self.y[:10000],\n",
    "            self.cnn_dropout_keep_prob : 1.0,\n",
    "            self.lstm_dropout_keep_prob : 1.0\n",
    "        }\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        with tf.Session(config = config, graph = self.graph) as self.sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(self.n_epochs):\n",
    "                for batch_index in range(n_batches):\n",
    "                    batch_x = self.x[batch_size * batch_index : (batch_index + 1) * batch_size]\n",
    "                    batch_y = self.y[batch_size * batch_index : (batch_index + 1) * batch_size]\n",
    "                    feed_dict = {\n",
    "                        self.input_x : batch_x,\n",
    "                        self.input_y : batch_y,\n",
    "                        self.cnn_dropout_keep_prob : self.cnn_drop_out_prob,\n",
    "                        self.lstm_dropout_keep_prob : self.lstm_drop_out_prob\n",
    "                    }\n",
    "                    self.sess.run(self.train_step, feed_dict = feed_dict)\n",
    "                    step = epoch * n_batches + batch_index\n",
    "                print('train epoch %d / %d Done' % (epoch, self.n_epochs))\n",
    "                if(epoch % 5 == 0):\n",
    "                    print('dev acc', self.train_acc.eval(feed_dict = dev_feed_dict))\n",
    "                    print('train loss', self.loss.eval(feed_dict = train_feed_dict))\n",
    "                    dev_acc_str = self.acc_sum.eval(feed_dict = dev_feed_dict)\n",
    "                    train_loss_str = self.loss_sum.eval(feed_dict = train_feed_dict)\n",
    "                    self.filewriter.add_summary(dev_acc_str, step)\n",
    "                    self.filewriter.add_summary(train_loss_str, step)\n",
    "\n",
    "m = CNNLSTM(max_seq_len, 5, 32, np.array(embedding_matrix), len(embedding_matrix[0]), [3], 8, learning_rate = 0.0001,\n",
    "            n_epochs = 1000, num_lstm_cells = 2)\n",
    "m.build()\n",
    "m.fit(train_x, train_y, dev_x, dev_y)\n",
    "m.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
