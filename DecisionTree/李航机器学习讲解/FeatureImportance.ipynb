{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征重要性算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息增益法 公式\n",
    "\n",
    "* 熵的定义：\n",
    "    * 属性 $ y $ 的熵，表示特征的不确定性：\n",
    "    $$ \n",
    "    P\\left(Y=y_{j}\\right)=p_{j}, \\quad i=1,2, \\cdots, n\n",
    "    $$\n",
    "    $$\n",
    "    H(Y)=-\\sum_{j=1}^{n} p_{j} \\log p_{j}\n",
    "    $$\n",
    "    \n",
    "* 条件熵的定义：\n",
    "    * 在 $ x $ 已知的情况下，$ y $ 的不确定性\n",
    "    $$ \n",
    "    P\\left(X=x_{i}, Y=y_{j}\\right)=p_{i j}, \\quad i=1,2, \\cdots, n ; \\quad j=1,2, \\cdots, m\n",
    "    $$\n",
    "    $$ \n",
    "    H(Y | X)=\\sum_{i=1}^{n} p_{i} H\\left(Y | X=x_{i}\\right)\n",
    "    $$\n",
    "\n",
    "* 信息增益计算流程\n",
    "    1. 计算特征A对数据集D的熵，即计算$ y $ 的熵\n",
    "    $$ \n",
    "    H(D)=-\\sum_{k=1}^{K} \\frac{\\left|C_{k}\\right|}{|D|} \\log _{2} \\frac{\\left|C_{k}\\right|}{|D|}\n",
    "    $$\n",
    "    2. 计算$ x $不同取值的情况下，$ y $的熵\n",
    "    $$ \n",
    "    H(D | A)=\\sum_{i=1}^{n} \\frac{\\left|D_{i}\\right|}{|D|} H\\left(D_{i}\\right)=-\\sum_{i=1}^{n} \\frac{\\left|D_{i}\\right|}{|D|} \\sum_{k=1}^{K} \\frac{\\left|D_{i k}\\right|}{\\left|D_{i}\\right|} \\log _{2} \\frac{\\left|D_{i k}\\right|}{\\left|D_{i}\\right|}\n",
    "    $$\n",
    "    3. 做差计算增益\n",
    "    $$ \n",
    "    g(D, A)=H(D)-H(D | A)\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "熵的计算\n",
    "'''\n",
    "def entropy(y_values):\n",
    "    e = 0\n",
    "    unique_vals = np.unique(y_values)\n",
    "    for val in unique_vals:\n",
    "        p = np.sum(y_values == val)/len(y_values)\n",
    "        e += (p * math.log(p, 2))\n",
    "    return -1 * e\n",
    "\n",
    "'''\n",
    "条件熵的计算\n",
    "'''\n",
    "def entropy_condition(x_values, y_values):\n",
    "    ey = entropy(y_values)\n",
    "    ey_condition = 0\n",
    "    xy = np.hstack((x_values, y_values))\n",
    "    unique_x = np.unique(x_values)\n",
    "    for x_val in unique_x:\n",
    "        px = np.sum(x_values == x_val) / len(x_values)\n",
    "        xy_condition_x = xy[np.where(xy[:, 0] == x_val)]\n",
    "        ey_condition_x = entropy(xy_condition_x[:, 1])\n",
    "        ey_condition += (px * ey_condition_x)\n",
    "    return ey - ey_condition\n",
    "\n",
    "'''\n",
    "信息增益比：摒弃了选择取值多的特征为重要特征的缺点\n",
    "'''\n",
    "def entropy_condition_ratio(x_values, y_values):\n",
    "    return entropy_condition(x_values, y_values) / entropy(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 以书中P62页的例子作为测试，以下分别为A1， A2的信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08300749985576883\n",
      "0.32365019815155627\n",
      "0.4199730940219749\n",
      "0.36298956253708536\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[0,0,0,0,0,1,1,1,1,1,2,2,2,2,2], [0,0,1,1,0,0,0,1,0,0,0,0,1,1,0], [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0], \n",
    "             [0,1,1,0,0,0,1,1,2,2,2,1,1,2,0], [0,0,1,1,0,0,0,1,1,1,1,1,1,1,0]]).T\n",
    "#A1\n",
    "print(entropy_condition(xy[:, 0].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "#A2\n",
    "print(entropy_condition(xy[:, 1].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A3\n",
    "print(entropy_condition(xy[:, 2].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A4\n",
    "print(entropy_condition(xy[:, 3].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 与书中结果相合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05237190142858302\n",
      "0.3524465495205019\n",
      "0.4325380677663126\n",
      "0.23185388128724224\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[0,0,0,0,0,1,1,1,1,1,2,2,2,2,2], [0,0,1,1,0,0,0,1,0,0,0,0,1,1,0], [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0], \n",
    "             [0,1,1,0,0,0,1,1,2,2,2,1,1,2,0], [0,0,1,1,0,0,0,1,1,1,1,1,1,1,0]]).T\n",
    "#A1\n",
    "print(entropy_condition_ratio(xy[:, 0].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "#A2\n",
    "print(entropy_condition_ratio(xy[:, 1].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A3\n",
    "print(entropy_condition_ratio(xy[:, 2].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A4\n",
    "print(entropy_condition_ratio(xy[:, 3].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基尼指数 公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\operatorname{Gini}(p)=\\sum_{k=1}^{K} p_{k}\\left(1-p_{k}\\right)=1-\\sum_{k=1}^{K} p_{k}^{2}\n",
    " $$\n",
    " $$ \n",
    "\\operatorname{Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2}\n",
    " $$\n",
    " $$ \n",
    "\\operatorname{Gini}(D, A)=\\frac{\\left|D_{1}\\right|}{|D|} \\operatorname{Gini}\\left(D_{1}\\right)+\\frac{\\left|D_{2}\\right|}{|D|} \\operatorname{Gini}\\left(D_{2}\\right)\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "基尼指数计算\n",
    "'''\n",
    "def gini(y_values):\n",
    "    g = 0\n",
    "    unique_vals = np.unique(y_values)\n",
    "    for val in unique_vals:\n",
    "        p = np.sum(y_values == val)/len(y_values)\n",
    "        g += (p * p)\n",
    "    return 1 - g\n",
    "\n",
    "'''\n",
    "按照x取值的基尼指数的计算\n",
    "'''\n",
    "def gini_condition(x_values, y_values):\n",
    "    g_condition = {}\n",
    "    xy = np.hstack((x_values, y_values))\n",
    "    unique_x = np.unique(x_values)\n",
    "    for x_val in unique_x:\n",
    "        xy_condition_x = xy[np.where(xy[:, 0] == x_val)]\n",
    "        xy_condition_notx = xy[np.where(xy[:, 0] != x_val)]\n",
    "        g_condition[x_val] = len(xy_condition_x)/len(x_values) * gini(xy_condition_x[:, 1]) + len(xy_condition_notx)/len(x_values) * gini(xy_condition_notx[:, 1])\n",
    "    return g_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.44, 1: 0.4799999999999999, 2: 0.43999999999999995}\n",
      "{0: 0.31999999999999995, 1: 0.31999999999999995}\n",
      "{0: 0.26666666666666666, 1: 0.26666666666666666}\n",
      "{0: 0.31999999999999984, 1: 0.4740740740740741, 2: 0.3636363636363637}\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[0,0,0,0,0,1,1,1,1,1,2,2,2,2,2], [0,0,1,1,0,0,0,1,0,0,0,0,1,1,0], [0,0,0,1,0,0,0,1,1,1,1,1,0,0,0], \n",
    "             [0,1,1,0,0,0,1,1,2,2,2,1,1,2,0], [0,0,1,1,0,0,0,1,1,1,1,1,1,1,0]]).T\n",
    "#A1\n",
    "print(gini_condition(xy[:, 0].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "#A2\n",
    "print(gini_condition(xy[:, 1].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A3\n",
    "print(gini_condition(xy[:, 2].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n",
    "\n",
    "#A4\n",
    "print(gini_condition(xy[:, 3].reshape(-1, 1), \n",
    "                        xy[:, -1].reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 与书中p71相符，选择最小的特征及$ x $取值作为最优特征及分切点。\n",
    "* 其实选取基尼指数最小，即选择在哪个特征下以及该特征取哪个值的情况下，$ y $的不确定性最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征重要性的对比\n",
    "### 以随机森林算法进行特征重要性计算，以书中数据为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16228836 0.29464286 0.44417989 0.09888889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42).fit(xy[:, :-1], xy[:, -1])\n",
    "\n",
    "print(rf. feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 总体上相符"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
